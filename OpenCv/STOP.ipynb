{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8prkEhETWbfm"
   },
   "outputs": [],
   "source": [
    "!pip3 install opencv-contrib-python\n",
    "!pip3 install matplotlib\n",
    "!pip3 install numpy\n",
    "!pip3 install rembg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mJ-jYkiYJq1q"
   },
   "outputs": [],
   "source": [
    "!pip3 install torch==1.7.1+cpu torchvision==0.8.2+cpu torchaudio===0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip3 install easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# background\n",
    "\n",
    "\n",
    "# import PIL module\n",
    "from PIL import Image\n",
    "  \n",
    "# Front Image\n",
    "filename = 'Train_5/Training/BK/N17.svg.png'\n",
    "# Back Image\n",
    "filename1 = 'Train_5/Training/BK/BG.jpg'\n",
    "  \n",
    "# Open Front Image\n",
    "frontImage = Image.open(filename)\n",
    "\n",
    "  \n",
    "# Open Background Image\n",
    "background = Image.open(filename1)\n",
    "  \n",
    "# Convert image to RGBA\n",
    "frontImage = frontImage.convert(\"RGBA\")\n",
    "  \n",
    "# Convert image to RGBA\n",
    "background = background.convert(\"RGBA\")\n",
    "  \n",
    "# Calculate width to be at the center\n",
    "width = (background.width - frontImage.width) // 2\n",
    "  \n",
    "# Calculate height to be at the center\n",
    "height = (background.height - frontImage.height) // 2\n",
    "  \n",
    "# Paste the frontImage at (width, height)\n",
    "background.paste(frontImage, (width, height), frontImage)\n",
    "  \n",
    "# Save this image\n",
    "background.save(\"Train_5/Training/BK/N17.png\", format=\"png\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frontImage.size)\n",
    "print(background.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Background colour\n",
    "\n",
    "\n",
    "RED =0\n",
    "GREEN =0\n",
    "BLUE =255\n",
    "ALPHA = 200\n",
    "Image = cv2.imread(\"Train/Train_Neg_13.svg.png\", cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "trasn_mask = Image[:,:,3 ]==0\n",
    "\n",
    "Image[trasn_mask]=[BLUE, GREEN, RED, ALPHA]\n",
    "cv2.imwrite(\"Train/output.png\", Image)\n",
    "#print(Image.shape)\n",
    "#resized = cv.resize(Image, None, fx=0.5, fy=0.5)\n",
    "#cv.imshow('windows', resized)\n",
    "#cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_webp = 'Train/Train_Neg_11.svg'\n",
    "image_png = 'Train/Train_Neg_11.png'\n",
    "\n",
    "im = Image.open(image_webp)\n",
    "im.save(image_png, format=\"png\", lossless=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pixellib\n",
    "import pixellib\n",
    "from pixellib.tune_bg import alter_bg\n",
    "\n",
    "change_bg = alter_bg()\n",
    "change_bg.load_pascalvoc_model(\"deeplabv3_xception_tf_dim_ordering_tf_kernels.h5\")\n",
    "change_bg.change_bg_img(f_image_path = \"Train_5/Stop_sign.png\",b_image_path = \"Train_5/BK1.jpg\", output_image_name=\"Train_5/new_img.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from skimage import transform\n",
    "\n",
    "def rotate_20_rand(X):\n",
    "    result = 255*transform.rotate(X, angle=np.random.uniform(-20, 20), mode='edge')\n",
    "    result = result.astype(np.uint8)\n",
    "    return result\n",
    "\n",
    "test_image = cv2.imread('Train_5/Stop_sign.png')\n",
    "#plt.imshow(test_image)\n",
    "image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "\n",
    "image = rotate_20_rand(image)\n",
    "#fig, axaxarray = plt.subplots(1,1)\n",
    "#axaxarray.imshow(rotate_20_rand(test_image), interpolation='nearest')\n",
    "#axaxarray.set_title(\"Rotation\")\n",
    "plt.imshow(image)\n",
    "plt.savefig('Train_5/image2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Q0jJmccUI-Kd"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import easyocr\n",
    "import matplotlib.pyplot as plt\n",
    "from rembg import remove\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "from scipy.interpolate import splprep, splev\n",
    "from spellchecker import SpellChecker\n",
    "spell = SpellChecker()\n",
    "import re\n",
    "from textblob import Word\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_area = image.size*(1/200)\n",
    "min_area = 2000\n",
    "alpha = .006\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15))\n",
    "colors_list = ['red', 'blue', 'green', 'black', 'white', 'yellow']\n",
    "def get_max_area(image):\n",
    "    return image.size/3.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pytesseract.pytesseract.tesseract_cmd = 'C:\\Program Files (x86)\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = '/opt/homebrew/bin/tesseract'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install textblob\n",
    "word = Word('stopl')\n",
    "result = word.correct()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign_name(path):\n",
    "    file_name = os.path.basename(path)\n",
    "    Name = os.path.splitext(file_name)[0]\n",
    "    return Name.lower()\n",
    "\n",
    "\n",
    "def write_name(path, Extract_path):\n",
    "    Name = sign_name(path)\n",
    "    with open(Extract_path, \"a+\") as file:\n",
    "        file.write(\"\\n \\n % traffic_sign({}, stop).\".format(Name))\n",
    "    file.close()\n",
    "\n",
    "\n",
    "    \n",
    "def has_color(items, path, Extract_path):\n",
    "    with open(Extract_path, \"a+\") as file:\n",
    "        for item in items:\n",
    "            # write each item on a new line\n",
    "            file.write(\"\\n has_color({},{}).\".format(sign_name(path), item))\n",
    "    #print('Done')\n",
    "    file.close()\n",
    "    \n",
    "def has_shape(items, path, Extract_path):\n",
    "    with open(Extract_path, \"a+\") as file:\n",
    "        for item in items:\n",
    "            # write each item on a new line\n",
    "            file.write(\"\\n has_shape({},{}).\".format(sign_name(path),item))\n",
    "    #print('Done')\n",
    "    file.close()\n",
    "    \n",
    " \n",
    "    \n",
    "def has_external_shape(shape, path, Extract_path):    \n",
    "    with open(Extract_path, \"a+\") as file: \n",
    "        # write each item on a new line\n",
    "        file.write(\"\\n has_external_shape({},{}).\".format(sign_name(path),shape))\n",
    "    #print('Done')\n",
    "    file.close()  \n",
    "\n",
    "    \n",
    "# A text file is created and flushed\n",
    "def has_word_(item, path, Extract_path):\n",
    "    with open(Extract_path, \"a+\") as file:\n",
    "        for idx, item in enumerate(item):\n",
    "            i = idx+1\n",
    "            if item.isdigit():\n",
    "                file.write(\"\\n has_number({},{}_{}).\".format(sign_name(path), sign_name(path), i))\n",
    "                file.write(\"\\n has_digits({}_{},{}).\".format(sign_name(path), i, list(item)))\n",
    "            else:\n",
    "                file.write(\"\\n has_word({},{}_{}).\".format(sign_name(path), sign_name(path), i))\n",
    "                n , com =commonCharacterCount('STOP', item)\n",
    "                #print(item)\n",
    "                #print(n)\n",
    "                if n>2:\n",
    "                    #file.write(\"\\n nearly_match_letters({}_{}, {}).\".format(sign_name(path), i,  list('stop')))\n",
    "                    file.write(\"\\n nearly_match_letters({}_{}, {}).\".format(sign_name(path), i, 'stop'))\n",
    "\n",
    "                # write each item on a new line\n",
    "                file.write(\"\\n has_letters({}_{},{}).\".format(sign_name(path), i,list(item.lower())))\n",
    "\n",
    "                if item.isupper():\n",
    "                    file.write(\"\\n font_case({}_{}, uppercase).\".format(sign_name(path), i))\n",
    "                elif item.islower():\n",
    "                    file.write(\"\\n font_case({}_{}, lowercase).\".format(sign_name(path), i))\n",
    "                else:\n",
    "                    file.write(\"\\n font_case({}_{}, mixed).\".format(sign_name(path), i))\n",
    "\n",
    "    #print('Done')\n",
    "    file.close()\n",
    "    \n",
    "    \n",
    "def commonCharacterCount(s1, s2):\n",
    "    a=list(set(s1)&set(s2))\n",
    "    return(len(a), a)        \n",
    "\n",
    "\n",
    "def nearly_match(item):\n",
    "    List = [ 'down', 'stop', 'work', 'enter', 'not', 'give', 'way']\n",
    "    #print('item=', item)\n",
    "    m = len(item)\n",
    "    OUT = []\n",
    "    if m!= 0:\n",
    "        item = item.lower()\n",
    "        print('item=', item)\n",
    "        print('item=', item)\n",
    "        for word in List:\n",
    "            s = len(word)\n",
    "            n , com =commonCharacterCount(word, item )\n",
    "            print(n/max(m,s))\n",
    "            if n/max(m,s)>0.5:\n",
    "                OUT.append(word)\n",
    "\n",
    "    print(\"finalout=\", OUT)\n",
    "    return OUT\n",
    "\n",
    "\n",
    "# A text file is created and flushed\n",
    "def has_word(item, path, Extract_path):\n",
    "    items = list(dict.fromkeys(item))\n",
    "    print('items=', items)\n",
    "    with open(Extract_path, \"a+\") as file:\n",
    "        for idx, item in enumerate(items):\n",
    "            i = idx+1\n",
    "            if item.isdigit():\n",
    "                file.write(\"\\n has_number({},{}_{}).\".format(sign_name(path), sign_name(path), i))\n",
    "                file.write(\"\\n has_digits({}_{},{}).\".format(sign_name(path), i, item))\n",
    "            else:\n",
    "                \n",
    "                #corrected = spell.correction(item)\n",
    "                print('item=', item)\n",
    "                word = Word(item)\n",
    "                corrected = word.correct()\n",
    "                print('corrected=', corrected)\n",
    "\n",
    "                word = nearly_match(item)\n",
    "\n",
    "                print('word=', word)\n",
    "                word = ''.join(word)\n",
    "                print('word=', word)\n",
    "                #if word == 'NONE':\n",
    "                #    file.write(\"\\n Other_letters({}_{}, {}).\".format(sign_name(path), i, word))\n",
    "                #else:\n",
    "                if len(word) > 1:\n",
    "                    file.write(\"\\n has_word({},{}_{}).\".format(sign_name(path), sign_name(path), i))\n",
    "                    file.write(\"\\n nearly_match_letters({}_{}, {}).\".format(sign_name(path), i, word))\n",
    "                    #if item.isupper():\n",
    "                    #    file.write(\"\\n font_case({}_{}, uppercase).\".format(sign_name(path), i))\n",
    "                    #elif item.islower():\n",
    "                    #    file.write(\"\\n font_case({}_{}, lowercase).\".format(sign_name(path), i))\n",
    "                    #else:\n",
    "                    #    file.write(\"\\n font_case({}_{}, mixed).\".format(sign_name(path), i))\n",
    "\n",
    "    #print('Done')\n",
    "    file.close()\n",
    "    \n",
    "    \n",
    "def recognize_text_(image):\n",
    "    '''loads an image and recognizes text.'''\n",
    "    reader = easyocr.Reader(['en'])\n",
    "    #image= remove_noise_T(image)\n",
    "\n",
    "    result = reader.readtext(image, detail=1, paragraph=False)\n",
    "    texts = []\n",
    "    for (bbox, text, prob) in result:\n",
    "        if prob >= 0.2:\n",
    "            # display \n",
    "            #print(f'Detected text: {text} (Probability: {prob:.2f})')\n",
    "            texts.append(text)\n",
    "    return texts\n",
    "            \n",
    "        \n",
    "    \n",
    "def recognize_text__(image):\n",
    "    '''loads an image and recognizes text.'''\n",
    "    reader = easyocr.Reader(['en'])\n",
    "    #image= remove_noise_T(image)\n",
    "\n",
    "    result = reader.readtext(image, detail=1, paragraph=False)\n",
    "    result1= reader.readtext(getcolormask('red', image), detail=1, paragraph=False)\n",
    "    result2= reader.readtext(getcolormask('white', image), detail=1, paragraph=False)\n",
    "\n",
    "    #result3= reader.readtext(getcolormask('black', image), detail=1, paragraph=False)\n",
    "    print('result=',result)\n",
    "    print('result1=',result1)\n",
    "    print('result2=',result2)\n",
    "    \n",
    "\n",
    "    texts = []\n",
    "    for (bbox, text, prob) in result:\n",
    "        getVals = list([val for val in text if val.isalpha() or val.isnumeric()])\n",
    "        text = \"\".join(getVals)\n",
    "        if prob >= 0.1 and text is not None:\n",
    "            # display \n",
    "            #print(f'Detected text: {text} (Probability: {prob:.2f})')\n",
    "            texts.append(text)\n",
    "    for (bbox, text, prob) in result1:\n",
    "        getVals = list([val for val in text if val.isalpha() or val.isnumeric()])\n",
    "        text = \"\".join(getVals)\n",
    "        if prob >= 0.1 and text is not None:\n",
    "            # display \n",
    "            #print(f'Detected text: {text} (Probability: {prob:.2f})')\n",
    "            texts.append(text)\n",
    "\n",
    "    for (bbox, text, prob) in result2:\n",
    "        getVals = list([val for val in text if val.isalpha() or val.isnumeric()])\n",
    "        text = \"\".join(getVals)\n",
    "        if prob >= 0.1 and text is not None:\n",
    "            # display \n",
    "            #print(f'Detected text: {text} (Probability: {prob:.2f})')\n",
    "            texts.append(text)\n",
    "\n",
    "    texts = list( dict.fromkeys(texts)) \n",
    "    return texts\n",
    "\n",
    "\n",
    "def recognize_text__(image):\n",
    "    '''loads an image and recognizes text.'''\n",
    "    img = image.copy()\n",
    "    img= remove_noise_T(img)\n",
    "    custom_config = r'--oem 3 --psm 13'\n",
    "    text = pytesseract.image_to_string(img, config=custom_config)\n",
    "    print(text)\n",
    "    return text\n",
    "\n",
    "def recognize_text(image):\n",
    "    '''loads an image and recognizes text.'''\n",
    "    reader = easyocr.Reader(['en'])\n",
    "    #image= remove_noise_T(image)\n",
    "\n",
    "    result = reader.readtext(image, detail=1, paragraph=False)\n",
    "    texts = []\n",
    "    for (bbox, text, prob) in result:\n",
    "        getVals = list([val for val in text if val.isalpha() or val.isnumeric()])\n",
    "        text = \"\".join(getVals)\n",
    "        if prob >= 0.1 and text is not None:\n",
    "            # display \n",
    "            #print(f'Detected text: {text} (Probability: {prob:.2f})')\n",
    "            texts.append(text)\n",
    "    texts = list( dict.fromkeys(texts)) \n",
    "    return texts\n",
    "\n",
    "def recognize_text_1(image):\n",
    "    '''loads an image and recognizes text.'''\n",
    "    img = image.copy()\n",
    "    img = get_contours(img)\n",
    "    smoothened = get_smoothened(contours)\n",
    "    stencil  = np.zeros(image.shape[:-1]).astype(np.uint8)\n",
    "    stencil[:] = 160\n",
    "\n",
    "        # Overlay the smoothed contours on the original image\n",
    "    cv2.drawContours(stencil, smoothened, -1, (255,0,255), thickness=cv2.FILLED)\n",
    "\n",
    "    text = pytesseract.image_to_string(stencil, config='--psm 13')\n",
    "    print(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#get colour mask\n",
    "def getcolormask(color, image):  \n",
    "    if color == 'red':\n",
    "        #lower_bound = np.array([160,50,50])\n",
    "        #upper_bound = np.array([180,255,255])\n",
    "        lower_bound_red = np.array([130,20,70])\n",
    "        upper_bound_red = np.array([180,255,255])\n",
    "        lower_bound_orange = np.array([0, 70, 25])\n",
    "        upper_bound_orange = np.array([25, 255, 255])\n",
    "        mask_red = cv2.inRange(get_hsv(image), lower_bound_red, upper_bound_red)\n",
    "        mask_orange = cv2.inRange(get_hsv(image), lower_bound_orange, upper_bound_orange)\n",
    "        mask = mask_orange + mask_red\n",
    "        \n",
    "\n",
    "\n",
    "    elif color == 'green':\n",
    "        lower_bound = np.array([50, 20, 20])   \n",
    "        upper_bound = np.array([100, 255, 255])\n",
    "        mask = cv2.inRange(get_hsv(image), lower_bound, upper_bound)\n",
    "\n",
    "    elif color == 'blue':\n",
    "        #lower_bound = np.array([108,50,38])\n",
    "        #upper_bound = np.array([120,255,255])\n",
    "        lower_bound = np.array([100,150,0])\n",
    "        upper_bound = np.array([140,255,255])\n",
    "        mask = cv2.inRange(get_hsv(image), lower_bound, upper_bound)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    elif color == 'black':\n",
    "        lower_bound = np.array([0, 0, 0])\n",
    "        upper_bound = np.array([[180, 255, 40]]) \n",
    "        mask = cv2.inRange(get_hsv(image), lower_bound, upper_bound)\n",
    "\n",
    "    elif color == 'white':\n",
    "        lower_bound = np.array([0,0,168])\n",
    "        upper_bound = np.array([172,111,255])\n",
    "        #lower_bound = np.array([0, 0, 10])\n",
    "        #upper_bound = np.array([255, 120, 255])\n",
    "        mask = cv2.inRange(get_hsv(image), lower_bound, upper_bound)\n",
    "\n",
    "    elif color == 'yellow':\n",
    "        lower_bound = np.array([20, 80, 80])\n",
    "        upper_bound = np.array([30, 255, 255])\n",
    "        mask = cv2.inRange(get_hsv(image), lower_bound, upper_bound)\n",
    "\n",
    "    mask = post_process(mask)\n",
    "    return mask\n",
    "\n",
    "\n",
    " \n",
    "    \n",
    "def get_color(image):    \n",
    "    max_area = get_max_area(image)\n",
    "\n",
    "    colors_present =[]\n",
    "    contour_list = []\n",
    "    for color in colors_list:\n",
    "        mask = getcolormask(color , image)\n",
    "\n",
    "        if cv2.countNonZero(mask) > min_area:\n",
    "\n",
    "            contours, hierarchy = cv2.findContours(mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "            if len(contours)>2:\n",
    "                #print(color)\n",
    "                colors_present.append(color)\n",
    "            else:\n",
    "                cnt_max = max(contours, key = cv2.contourArea)\n",
    "                area = cv2.contourArea(cnt_max) \n",
    "                #print(\"{},{}\".format(color, area))\n",
    "                if (area > min_area) and (area < max_area ) :\n",
    "                    colors_present.append(color)\n",
    "    colors_present = list(dict.fromkeys(colors_present))\n",
    "    return colors_present\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# find contours via color mask\n",
    "def get_contours(image):\n",
    "    contour_list = []\n",
    "    for color in colors_list:\n",
    "        mask = getcolormask(color , image)\n",
    "        if cv2.countNonZero(mask) > min_area:\n",
    "            contours, hierarchy = cv2.findContours(mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "            for cnt in contours: \n",
    "                if cv2.contourArea(cnt, True)>0:    #Consider only clockwise contours\n",
    "                    contour_list.append(cnt)\n",
    "#    cnt_max = max(contour_list, key = cv2.contourArea)\n",
    "#    contour_list.remove(cnt_max)\n",
    "#    cv2.drawContours(image, contour_list,  -1, (0,255,0), 8)\n",
    "#    print(len(contour_list))\n",
    "    return contour_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# find biggest contours\n",
    "def get_external_contour(image):    \n",
    "    max_area = get_max_area(image)\n",
    "\n",
    "    contours = get_contours(image)\n",
    "    cnt = max(contours, key = cv2.contourArea)\n",
    "    area = cv2.contourArea(cnt)\n",
    "    if (area > min_area) and (area < max_area ):\n",
    "        cnt_max=cnt\n",
    "    else:\n",
    "        contours.remove(cnt)\n",
    "        cnt_max = max(contours, key = cv2.contourArea)\n",
    "    \n",
    "    #cv2.drawContours(image, cnt_max,  -1, (255,0,0), 5)\n",
    "    return cnt_max\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_external_shape(image):\n",
    " #   remove_bg(image)\n",
    "    cnt = get_external_contour(image) \n",
    "    #cv2.drawContours(image, cnt,  -1, (0,255,0), 2)\n",
    "    approx = cv2.approxPolyDP(cnt, alpha*cv2.arcLength(cnt, True), True)\n",
    "    #print(len(approx))\n",
    "    (x, y, w, h) = cv2.boundingRect(approx)\n",
    "    ar = w / float(h)\n",
    "    #print(len(approx))\n",
    "    if len(approx) == 3 : #and cv2.isContourConvex(cnt)\n",
    "        shape = \"triangle\"\n",
    "    elif len(approx) == 4 :\n",
    "        shape = \"rectangle\"\n",
    "    elif len(approx) == 5 :\n",
    "        shape = \"pentagon\"\n",
    "    elif len(approx) == 6 :\n",
    "        shape = \"hexagon\"\n",
    "    elif len(approx) == 8:\n",
    "        if ar >= 0.95 and ar <= 1.05 :\n",
    "            shape = \"octagon\"\n",
    "        else:\n",
    "            shape = \"other\"\n",
    "    elif 14 < len(approx) < 20 and ar >= 0.95 and ar <= 1.05 :\n",
    "        shape = \"circle\"\n",
    "    else:\n",
    "        shape = \"other\"\n",
    "    return shape\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def get_shape(image):\n",
    "    max_area = get_max_area(image)\n",
    "    \n",
    "    shape_list = [] \n",
    "    contours = get_contours(image)\n",
    "    cv2.drawContours(image, contours,  -1, (0,255,255), 12)\n",
    "    \n",
    "#    print(len(contours))\n",
    "\n",
    "    #print(len(contours))\n",
    "#    cnt_max = max(contours, key = cv2.contourArea)\n",
    "#    contours.remove(cnt_max)\n",
    "\n",
    "#    print(len(contours))\n",
    "\n",
    "#    cv2.drawContours(image, contours,  -1, (0,255,0), 3)\n",
    "\n",
    "    for cnt in contours:\n",
    "\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if (area > min_area) and (area < max_area ) :\n",
    "            approx = cv2.approxPolyDP(cnt, alpha*cv2.arcLength(cnt, True), True)\n",
    "            (x, y, w, h) = cv2.boundingRect(approx)\n",
    "\n",
    "            ar = w / float(h)\n",
    "            #print(len(approx))\n",
    "            if len(approx) == 3 :\n",
    "                shape = \"triangle\"\n",
    "            elif len(approx) == 4 :\n",
    "                 shape = \"rectangle\"\n",
    "            elif len(approx) == 5 :\n",
    "                shape = \"pentagon\"\n",
    "            elif len(approx) == 6 :\n",
    "                shape = \"hexagon\"\n",
    "            elif len(approx) == 8:\n",
    "                if ar >= 0.95 and ar <= 1.05 :\n",
    "                    shape = \"octagon\"\n",
    "                else:\n",
    "                    #print('T')\n",
    "                    shape = \"other\"\n",
    "            elif 14 < len(approx) < 20:\n",
    "                if ar >= 0.95 and ar <= 1.05 :\n",
    "                    shape = \"circle\" \n",
    "                    cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "                else:\n",
    "                    shape = \"other\" \n",
    "                    #print(ar)\n",
    "#                    cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            else:\n",
    "                shape = \"other\"\n",
    "                #print(len(approx))\n",
    "#                cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,255),4)\n",
    "                #cv2.drawContours(image, approx,  -1, (0,255,0), 13)\n",
    "            shape_list.append(shape)\n",
    "#ß    my_dict = {i:shape_list.count(i) for i in shape_list}\n",
    "    shape_list = list(dict.fromkeys(shape_list))        \n",
    "    return shape_list\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def remove_bg_(image):\n",
    "#    image = remove_noise(image)\n",
    "    image = remove(image) \n",
    "    image = cv2.cvtColor(np.array(image), cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "    image = image.copy()\n",
    "\n",
    "    if len(image.shape) > 2 and image.shape[2] == 4:\n",
    "        image = image[:, :, :3]\n",
    "    contour = [get_external_contour(image)]\n",
    "    fill_color = [205,192,176] # any BGR color value to fill with\n",
    "    mask_value = 255            # 1 channel white (can be any non-zero uint8 value)\n",
    "    stencil  = np.zeros(image.shape[:-1]).astype(np.uint8)\n",
    "    cv2.fillPoly(stencil, contour, mask_value)\n",
    "    sel      = stencil != mask_value # select everything that is not mask_value\n",
    "    image[sel] = fill_color            # and fill it with fill_color\n",
    "\n",
    "    return image\n",
    "\n",
    "def remove_bg(image):\n",
    "    image = remove(image) \n",
    "    image = cv2.cvtColor(np.array(image), cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "    return cv2.medianBlur(image,5)\n",
    "\n",
    "#cv2.drawContours(img, contours,  -1, (255,0,0), 5)\n",
    "\n",
    "# objects = car, bike, arrow, man, animal, exclamation, bump, snowflake\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "def white_bg(image):\n",
    "    tmp = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)   ## Convert image to image gray\n",
    "    _, alpha = cv2.threshold(tmp, 0, 255, cv2.THRESH_BINARY)  # Applying thresholding technique\n",
    "    b, g, r = cv2.split(image) # Using cv2.split() to split channels of coloured image\n",
    "    rgba = [b, g, r, alpha] # Making list of Red, Green, Blue Channels and alpha\n",
    "    dst = cv2.merge(rgba, 4) # Using cv2.merge() to merge rgba into a coloured/multi-channeled image\n",
    "    plt.imshow(dst)\n",
    "    #cv2.imwrite(\"gfg_white.png\", dst) # Writing and saving to a new image\n",
    "    return dst\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_matchshape(image):\n",
    "    objects_list = []\n",
    "    contours = get_contours(image)\n",
    "    for cnt in contours:\n",
    "        for shape in objects:\n",
    "            if cv2.matchShapes(cnt,shape,1,0.0)>0.05:\n",
    "                objects_list.append(shape)\n",
    "    return(objects_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "# noise removal canny edge\n",
    "def remove_noise(image):\n",
    "    image = cv2.cvtColor(np.array(image), cv2.COLOR_BGRA2BGR)\n",
    "    bilateral_filtered_img = cv2.bilateralFilter(image, 5, 175, 175)\n",
    "    return cv2.Canny(bilateral_filtered_img, 70, 200)\n",
    "\n",
    "def remove_noise_(image):\n",
    "    image = cv2.cvtColor(np.array(image), cv2.COLOR_BGRA2BGR)\n",
    "    bilateral_filtered_img = cv2.bilateralFilter(image, 5, 175, 175)\n",
    "    edges = cv2.Canny(bilateral_filtered_img, 70, 200)\n",
    "#    lines = cv2.HoughLinesP(edges,1,np.pi/180,100,minLineLength,maxLineGap)\n",
    "    lines = cv2.HoughLinesP(edges,rho = 1,theta = 1*np.pi/180,threshold = 100,minLineLength = 100,maxLineGap = 5)\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        cv2.line(image, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
    "    return(image)\n",
    "\n",
    "def remove_noise_T(image):\n",
    "    image = cv2.cvtColor(np.array(image), cv2.COLOR_BGRA2BGR)\n",
    "    bilateral_filtered_img = cv2.bilateralFilter(image, 5, 175, 175)\n",
    "    blur = cv2.medianBlur(bilateral_filtered_img, 5) \n",
    "    return thresholding(blur)\n",
    "\n",
    "\n",
    "def remove_noise_Text(image):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    gray, img_bin = cv2.threshold(gray,128,255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    gray = cv2.bitwise_not(img_bin)\n",
    "    img = cv2.erode(gray, kernel, iterations=1)\n",
    "    img = cv2.dilate(img, kernel, iterations=1)\n",
    "    return(img)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# convert to hsv\n",
    "def get_hsv(image):\n",
    "    blur = cv2.medianBlur(image, 5)  #applying median filter to remove noice\n",
    "    #blur = cv2.GaussianBlur(image, (5,5), 0)\n",
    "    return cv2.cvtColor(blur,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "# noise removal\n",
    "def remove_noise2(image):\n",
    "    return cv2.medianBlur(image,5)\n",
    " \n",
    "#thresholding\n",
    "def thresholding(image):\n",
    "    gray= cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    return cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "#dilation\n",
    "def dilate(image):\n",
    "#    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.dilate(image, kernel, iterations = 1)\n",
    "    \n",
    "#erosion\n",
    "def erode(image):\n",
    "#    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.erode(image, kernel, iterations = 1)\n",
    "\n",
    "#opening - erosion followed by dilation\n",
    "def opening(image):\n",
    "#    kernel = np.ones((5,5),np.uint8)\n",
    "    opening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "    return remove_noise(opening)\n",
    "\n",
    "def gradient(image):\n",
    "#    kernel = np.ones((5,5),np.uint8)\n",
    "    gradient = cv2.morphologyEx(image, cv2.MORPH_GRADIENT, kernel)\n",
    "    return remove_noise(gradient)\n",
    "\n",
    "def approximate_contours(contours):\n",
    "    result = []\n",
    "    for x in contours:\n",
    "        epsilon = 0.005 * cv2.arcLength(x, True)\n",
    "        approx = cv2.approxPolyDP(x, epsilon, True)\n",
    "        result.append(approx)\n",
    "    return result\n",
    "\n",
    "#canny edge detection\n",
    "def canny(image):\n",
    "    return cv2.Canny(image, 100, 200)\n",
    "\n",
    "#skew correction\n",
    "def deskew(image):\n",
    "    coords = np.column_stack(np.where(image > 0))\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated\n",
    "\n",
    "def post_process(mask):\n",
    "    \"\"\"\n",
    "    Post Process the mask for a smooth boundary by applying Morphological Operations\n",
    "    Research based on paper: https://www.sciencedirect.com/science/article/pii/S2352914821000757\n",
    "    args:\n",
    "        mask: Binary Numpy Mask\n",
    "    \"\"\"\n",
    "    #closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    mask = cv2.GaussianBlur(mask, (5, 5), sigmaX=2, sigmaY=2, borderType=cv2.BORDER_DEFAULT)\n",
    "#    mask = np.where(mask < 127, 0, 255).astype(np.uint8)  # convert again to binary\n",
    "    #bilateral_filtered_img = cv2.bilateralFilter(mask, 9, 175, 175)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "\n",
    "def get_circle(image):\n",
    "    circles = cv2.HoughCircles(remove_noise(image), cv2.HOUGH_GRADIENT, 1.2, image.size/3000)\n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "    return circles \n",
    "\n",
    "def get_line(image):\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray,50,120)\n",
    "    minLineLength = 20\n",
    "    maxLineGap = 5\n",
    "    lines = cv2.HoughLinesP(edges,1,np.pi/180,100,minLineLength,maxLineGap)\n",
    "    for x1,y1,x2,y2 in lines[0]:\n",
    "        cv2.line(image,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "    return(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Extract_features(path):\n",
    "    \n",
    "    write_name(path, Extract_path)\n",
    "    img = cv2.imread(path)    \n",
    "    img = remove_bg(img)\n",
    "    image = cv2.cvtColor(np.array(img), cv2.COLOR_BGRA2BGR)\n",
    "    image = cv2.bilateralFilter(image, 5, 175, 175)\n",
    "    colors_present = get_color(image)\n",
    "    has_color(colors_present, path, Extract_path)        \n",
    "\n",
    "    result1 = recognize_text(remove_noise_T(img))\n",
    "    result1 = [name.lower() for name in result1]\n",
    "\n",
    "    result2 = recognize_text(img)\n",
    "    result2 = [name.lower() for name in result2]\n",
    "\n",
    "    result  = list(dict.fromkeys(result1 + result2))\n",
    "    print('result1=', result1)\n",
    "\n",
    "    print('result2=', result2)\n",
    "    print('result=', result)\n",
    "    has_word(result, path, Extract_path)\n",
    "\n",
    "    shape = get_shape(image)\n",
    "    has_shape(shape, path, Extract_path)\n",
    "\n",
    "    #external_shape = get_external_shape(img)\n",
    "    #has_external_shape(external_shape, path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_smoothened(contours):\n",
    "    smoothened = []\n",
    "    for contour in contours:\n",
    "        x,y = contour.T\n",
    "        # Convert from numpy arrays to normal arrays\n",
    "        x = x.tolist()[0]\n",
    "        y = y.tolist()[0]\n",
    "        # https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.interpolate.splprep.html\n",
    "        tck, u = splprep([x,y], u=None, s=1.0, per=1)\n",
    "        # https://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.linspace.html\n",
    "        u_new = np.linspace(u.min(), u.max(), 40)\n",
    "        # https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.interpolate.splev.html\n",
    "        x_new, y_new = splev(u_new, tck, der=0)\n",
    "        # Convert it back to numpy format for opencv to be able to display it\n",
    "        res_array = [[[int(i[0]), int(i[1])]] for i in zip(x_new,y_new)]\n",
    "        smoothened.append(np.asarray(res_array, dtype=np.int32))\n",
    "    return smoothened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity(contour):\n",
    "    object_list = []\n",
    "    for object in objects:\n",
    "        match = cv2.matchShapes(template_contour, c, 3, 0.0)\n",
    "        similarity = cv2.matchShapes(poly.reshape((poly.shape[0], 1, poly.shape[1])), contour, cv2.cv.CV_CONTOURS_MATCH_I2, 0)\n",
    "        if match < 0.15:\n",
    "            closest_contour = c\n",
    "        else:\n",
    "            closest_contour = [] \n",
    "        if similarity>.5:\n",
    "            object_list.append(object)\n",
    "    return object_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1= ['stop']\n",
      "result2= ['stop']\n",
      "result= ['stop']\n",
      "items= ['stop']\n",
      "item= stop\n",
      "corrected= stop\n",
      "item= stop\n",
      "item= stop\n",
      "0.25\n",
      "1.0\n",
      "0.25\n",
      "0.2\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "Train_5/Test/subtle/octnoise_10ft_0deg.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1= []\n",
      "result2= ['stop']\n",
      "result= ['stop']\n",
      "items= ['stop']\n",
      "item= stop\n",
      "corrected= stop\n",
      "item= stop\n",
      "item= stop\n",
      "0.25\n",
      "1.0\n",
      "0.25\n",
      "0.2\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "Train_5/Test/subtle/octnoise_10ft_15deg.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1= []\n",
      "result2= ['stop']\n",
      "result= ['stop']\n",
      "items= ['stop']\n",
      "item= stop\n",
      "corrected= stop\n",
      "item= stop\n",
      "item= stop\n",
      "0.25\n",
      "1.0\n",
      "0.25\n",
      "0.2\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "Train_5/Test/subtle/octnoise_10ft_30deg.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1= ['stop']\n",
      "result2= ['stop']\n",
      "result= ['stop']\n",
      "items= ['stop']\n",
      "item= stop\n",
      "corrected= stop\n",
      "item= stop\n",
      "item= stop\n",
      "0.25\n",
      "1.0\n",
      "0.25\n",
      "0.2\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "Train_5/Test/subtle/octnoise_15ft_0deg.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1= []\n",
      "result2= ['stopi']\n",
      "result= ['stopi']\n",
      "items= ['stopi']\n",
      "item= stopi\n",
      "corrected= stop\n",
      "item= stopi\n",
      "item= stopi\n",
      "0.2\n",
      "0.8\n",
      "0.2\n",
      "0.2\n",
      "0.4\n",
      "0.2\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "Train_5/Test/subtle/octnoise_15ft_15deg.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1= ['stqp']\n",
      "result2= ['stop']\n",
      "result= ['stqp', 'stop']\n",
      "items= ['stqp', 'stop']\n",
      "item= stqp\n",
      "corrected= step\n",
      "item= stqp\n",
      "item= stqp\n",
      "0.0\n",
      "0.75\n",
      "0.0\n",
      "0.2\n",
      "0.25\n",
      "0.0\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "item= stop\n",
      "corrected= stop\n",
      "item= stop\n",
      "item= stop\n",
      "0.25\n",
      "1.0\n",
      "0.25\n",
      "0.2\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "Train_5/Test/subtle/octnoise_20ft_0deg.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1= ['op']\n",
      "result2= ['stop']\n",
      "result= ['op', 'stop']\n",
      "items= ['op', 'stop']\n",
      "item= op\n",
      "corrected= op\n",
      "item= op\n",
      "item= op\n",
      "0.25\n",
      "0.5\n",
      "0.25\n",
      "0.0\n",
      "0.3333333333333333\n",
      "0.0\n",
      "0.0\n",
      "finalout= []\n",
      "word= []\n",
      "word= \n",
      "item= stop\n",
      "corrected= stop\n",
      "item= stop\n",
      "item= stop\n",
      "0.25\n",
      "1.0\n",
      "0.25\n",
      "0.2\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "Train_5/Test/subtle/octnoise_20ft_15deg.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1= ['stqpi']\n",
      "result2= ['stop']\n",
      "result= ['stqpi', 'stop']\n",
      "items= ['stqpi', 'stop']\n",
      "item= stqpi\n",
      "corrected= steps\n",
      "item= stqpi\n",
      "item= stqpi\n",
      "0.0\n",
      "0.6\n",
      "0.0\n",
      "0.2\n",
      "0.2\n",
      "0.2\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "item= stop\n",
      "corrected= stop\n",
      "item= stop\n",
      "item= stop\n",
      "0.25\n",
      "1.0\n",
      "0.25\n",
      "0.2\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "Train_5/Test/subtle/octnoise_25ft_0deg.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1= ['stqp']\n",
      "result2= ['stop']\n",
      "result= ['stqp', 'stop']\n",
      "items= ['stqp', 'stop']\n",
      "item= stqp\n",
      "corrected= step\n",
      "item= stqp\n",
      "item= stqp\n",
      "0.0\n",
      "0.75\n",
      "0.0\n",
      "0.2\n",
      "0.25\n",
      "0.0\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "item= stop\n",
      "corrected= stop\n",
      "item= stop\n",
      "item= stop\n",
      "0.25\n",
      "1.0\n",
      "0.25\n",
      "0.2\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "Train_5/Test/subtle/octnoise_30ft_0deg.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1= ['ctqp']\n",
      "result2= ['stop']\n",
      "result= ['ctqp', 'stop']\n",
      "items= ['ctqp', 'stop']\n",
      "item= ctqp\n",
      "corrected= step\n",
      "item= ctqp\n",
      "item= ctqp\n",
      "0.0\n",
      "0.5\n",
      "0.0\n",
      "0.2\n",
      "0.25\n",
      "0.0\n",
      "0.0\n",
      "finalout= []\n",
      "word= []\n",
      "word= \n",
      "item= stop\n",
      "corrected= stop\n",
      "item= stop\n",
      "item= stop\n",
      "0.25\n",
      "1.0\n",
      "0.25\n",
      "0.2\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "Train_5/Test/subtle/octnoise_40ft_0deg.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1= ['fop', '0']\n",
      "result2= ['istop']\n",
      "result= ['fop', '0', 'istop']\n",
      "items= ['fop', '0', 'istop']\n",
      "item= fop\n",
      "corrected= for\n",
      "item= fop\n",
      "item= fop\n",
      "0.25\n",
      "0.5\n",
      "0.25\n",
      "0.0\n",
      "0.3333333333333333\n",
      "0.0\n",
      "0.0\n",
      "finalout= []\n",
      "word= []\n",
      "word= \n",
      "item= istop\n",
      "corrected= stop\n",
      "item= istop\n",
      "item= istop\n",
      "0.2\n",
      "0.8\n",
      "0.2\n",
      "0.2\n",
      "0.4\n",
      "0.2\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "Train_5/Test/subtle/octnoise_5ft_0deg.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1= ['op']\n",
      "result2= ['stop']\n",
      "result= ['op', 'stop']\n",
      "items= ['op', 'stop']\n",
      "item= op\n",
      "corrected= op\n",
      "item= op\n",
      "item= op\n",
      "0.25\n",
      "0.5\n",
      "0.25\n",
      "0.0\n",
      "0.3333333333333333\n",
      "0.0\n",
      "0.0\n",
      "finalout= []\n",
      "word= []\n",
      "word= \n",
      "item= stop\n",
      "corrected= stop\n",
      "item= stop\n",
      "item= stop\n",
      "0.25\n",
      "1.0\n",
      "0.25\n",
      "0.2\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "Train_5/Test/subtle/octnoise_5ft_15deg.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1= []\n",
      "result2= ['stop']\n",
      "result= ['stop']\n",
      "items= ['stop']\n",
      "item= stop\n",
      "corrected= stop\n",
      "item= stop\n",
      "item= stop\n",
      "0.25\n",
      "1.0\n",
      "0.25\n",
      "0.2\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "Train_5/Test/subtle/octnoise_5ft_30deg.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1= []\n",
      "result2= ['stop']\n",
      "result= ['stop']\n",
      "items= ['stop']\n",
      "item= stop\n",
      "corrected= stop\n",
      "item= stop\n",
      "item= stop\n",
      "0.25\n",
      "1.0\n",
      "0.25\n",
      "0.2\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "Train_5/Test/subtle/octnoise_5ft_45deg.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1= []\n",
      "result2= ['topl']\n",
      "result= ['topl']\n",
      "items= ['topl']\n",
      "item= topl\n",
      "corrected= top\n",
      "item= topl\n",
      "item= topl\n",
      "0.25\n",
      "0.75\n",
      "0.25\n",
      "0.2\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "Train_5/Test/subtle/octnoise_5ft_60deg.jpg\n"
     ]
    }
   ],
   "source": [
    "#source_path = \"Train_5/Training\"\n",
    "\n",
    "source_path = \"Train_5/Training/*\"\n",
    "Extract_path = \"Train_5/Training/Training_BK.txt\"\n",
    "\n",
    "#source_path = \"Train_5/Test/subtle/*\"\n",
    "#Extract_path = \"Train_5/Test/subtle/bk_subtle.txt\"\n",
    "\n",
    "#source_path = \"Train_5/Test/LoveHate/*\"\n",
    "#Extract_path = \"Train_5/Test/LoveHate/bk_Love.txt\"\n",
    "\n",
    "#source_path = \"Train_5/Test/LoveHate/Angle/*\"\n",
    "#Extract_path = \"Train_5/Test/LoveHate/bk_Love_Angle.txt\"\n",
    "\n",
    "#source_path = \"Train_5/Test/BW Rectangles - GTSRB/*\"\n",
    "#Extract_path = \"Train_5/Test/BW Rectangles - GTSRB/bk_GTSRB.txt\"\n",
    "\n",
    "\n",
    "\n",
    "for filename in sorted(glob.iglob(source_path, recursive=True)):\n",
    "    if (filename.endswith(\".png\")) or (filename.endswith(\".jpeg\")) or (filename.endswith(\".jpg\")):\n",
    "        Extract_features(filename)\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = \"Train_5/Training\"\n",
    "\n",
    "Extract_path = \"Train_5/Training/background_knowledge.txt\"\n",
    "\n",
    "imdir = 'path/to/files/'\n",
    "ext = ['png', 'jpg', 'jpeg']    # Add image formats here\n",
    "\n",
    "try:\n",
    "    os.remove(Extract_path)\n",
    "except OSError:\n",
    "    pass\n",
    "#    results_file.write('hi\\n')\n",
    "with open(Extract_path, \"a+\") as file:\n",
    "    file.write(\"\\n \\n % In the name of Allah\")\n",
    "file.close()    \n",
    "    \n",
    "    \n",
    "files = []\n",
    "[files.extend(glob.glob(source_path + '*.' + e)) for e in ext]\n",
    "#print(files)\n",
    "\n",
    "#for filename in sorted(glob.iglob(source_path, recursive=True)):\n",
    "for filename in sorted(files):\n",
    "\n",
    "    Extract_features(filename)\n",
    "    print(filename)\n",
    "\n",
    "\n",
    "#for filename in sorted(glob.iglob(source_path, recursive=True)):\n",
    "#    Extract_features(filename)\n",
    "#    print(filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COvWuFg0jGhq"
   },
   "source": [
    "# New section"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
