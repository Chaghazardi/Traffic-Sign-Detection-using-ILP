{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8prkEhETWbfm"
   },
   "outputs": [],
   "source": [
    "!pip3 install opencv-contrib-python\n",
    "!pip3 install matplotlib\n",
    "!pip3 install numpy\n",
    "!pip3 install rembg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mJ-jYkiYJq1q"
   },
   "outputs": [],
   "source": [
    "!pip3 install torch==1.7.1+cpu torchvision==0.8.2+cpu torchaudio===0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip3 install easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# background\n",
    "\n",
    "\n",
    "# import PIL module\n",
    "from PIL import Image\n",
    "  \n",
    "# Front Image\n",
    "filename = 'Train_5/Training/BK/N17.svg.png'\n",
    "# Back Image\n",
    "filename1 = 'Train_5/Training/BK/BG.jpg'\n",
    "  \n",
    "# Open Front Image\n",
    "frontImage = Image.open(filename)\n",
    "\n",
    "  \n",
    "# Open Background Image\n",
    "background = Image.open(filename1)\n",
    "  \n",
    "# Convert image to RGBA\n",
    "frontImage = frontImage.convert(\"RGBA\")\n",
    "  \n",
    "# Convert image to RGBA\n",
    "background = background.convert(\"RGBA\")\n",
    "  \n",
    "# Calculate width to be at the center\n",
    "width = (background.width - frontImage.width) // 2\n",
    "  \n",
    "# Calculate height to be at the center\n",
    "height = (background.height - frontImage.height) // 2\n",
    "  \n",
    "# Paste the frontImage at (width, height)\n",
    "background.paste(frontImage, (width, height), frontImage)\n",
    "  \n",
    "# Save this image\n",
    "background.save(\"Train_5/Training/BK/N17.png\", format=\"png\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frontImage.size)\n",
    "print(background.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Background colour\n",
    "\n",
    "\n",
    "RED =0\n",
    "GREEN =0\n",
    "BLUE =255\n",
    "ALPHA = 200\n",
    "Image = cv2.imread(\"Train/Train_Neg_13.svg.png\", cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "trasn_mask = Image[:,:,3 ]==0\n",
    "\n",
    "Image[trasn_mask]=[BLUE, GREEN, RED, ALPHA]\n",
    "cv2.imwrite(\"Train/output.png\", Image)\n",
    "#print(Image.shape)\n",
    "#resized = cv.resize(Image, None, fx=0.5, fy=0.5)\n",
    "#cv.imshow('windows', resized)\n",
    "#cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_webp = 'Train/Train_Neg_11.svg'\n",
    "image_png = 'Train/Train_Neg_11.png'\n",
    "\n",
    "im = Image.open(image_webp)\n",
    "im.save(image_png, format=\"png\", lossless=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pixellib\n",
    "import pixellib\n",
    "from pixellib.tune_bg import alter_bg\n",
    "\n",
    "change_bg = alter_bg()\n",
    "change_bg.load_pascalvoc_model(\"deeplabv3_xception_tf_dim_ordering_tf_kernels.h5\")\n",
    "change_bg.change_bg_img(f_image_path = \"Train_5/Stop_sign.png\",b_image_path = \"Train_5/BK1.jpg\", output_image_name=\"Train_5/new_img.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from skimage import transform\n",
    "\n",
    "def rotate_20_rand(X):\n",
    "    result = 255*transform.rotate(X, angle=np.random.uniform(-20, 20), mode='edge')\n",
    "    result = result.astype(np.uint8)\n",
    "    return result\n",
    "\n",
    "test_image = cv2.imread('Train_5/Stop_sign.png')\n",
    "#plt.imshow(test_image)\n",
    "image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "\n",
    "image = rotate_20_rand(image)\n",
    "#fig, axaxarray = plt.subplots(1,1)\n",
    "#axaxarray.imshow(rotate_20_rand(test_image), interpolation='nearest')\n",
    "#axaxarray.set_title(\"Rotation\")\n",
    "plt.imshow(image)\n",
    "plt.savefig('Train_5/image2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Q0jJmccUI-Kd"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import easyocr\n",
    "import matplotlib.pyplot as plt\n",
    "from rembg import remove\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "from scipy.interpolate import splprep, splev\n",
    "from spellchecker import SpellChecker\n",
    "spell = SpellChecker()\n",
    "import re\n",
    "from textblob import Word\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_area = image.size*(1/200)\n",
    "min_area = 2000\n",
    "alpha = .006\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15))\n",
    "colors_list = ['red', 'blue', 'green', 'black', 'white', 'yellow']\n",
    "def get_max_area(image):\n",
    "    return image.size/3.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pytesseract.pytesseract.tesseract_cmd = 'C:\\Program Files (x86)\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = '/opt/homebrew/bin/tesseract'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install textblob\n",
    "word = Word('stopl')\n",
    "result = word.correct()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign_name(path):\n",
    "    file_name = os.path.basename(path)\n",
    "    Name = os.path.splitext(file_name)[0]\n",
    "    return Name.lower()\n",
    "\n",
    "\n",
    "def write_name(path, Extract_path):\n",
    "    Name = sign_name(path)\n",
    "    with open(Extract_path, \"a+\") as file:\n",
    "        file.write(\"\\n \\n % traffic_sign({}, stop).\".format(Name))\n",
    "    file.close()\n",
    "\n",
    "\n",
    "    \n",
    "def has_color(items, path, Extract_path):\n",
    "    with open(Extract_path, \"a+\") as file:\n",
    "        for item in items:\n",
    "            # write each item on a new line\n",
    "            file.write(\"\\n has_color({},{}).\".format(sign_name(path), item))\n",
    "    #print('Done')\n",
    "    file.close()\n",
    "    \n",
    "def has_shape(items, path, Extract_path):\n",
    "    with open(Extract_path, \"a+\") as file:\n",
    "        for item in items:\n",
    "            # write each item on a new line\n",
    "            file.write(\"\\n has_shape({},{}).\".format(sign_name(path),item))\n",
    "    #print('Done')\n",
    "    file.close()\n",
    "    \n",
    " \n",
    "    \n",
    "def has_external_shape(shape, path, Extract_path):    \n",
    "    with open(Extract_path, \"a+\") as file: \n",
    "        # write each item on a new line\n",
    "        file.write(\"\\n has_external_shape({},{}).\".format(sign_name(path),shape))\n",
    "    #print('Done')\n",
    "    file.close()  \n",
    "\n",
    "    \n",
    "# A text file is created and flushed\n",
    "def has_word_(item, path, Extract_path):\n",
    "    with open(Extract_path, \"a+\") as file:\n",
    "        for idx, item in enumerate(item):\n",
    "            i = idx+1\n",
    "            if item.isdigit():\n",
    "                file.write(\"\\n has_number({},{}_{}).\".format(sign_name(path), sign_name(path), i))\n",
    "                file.write(\"\\n has_digits({}_{},{}).\".format(sign_name(path), i, list(item)))\n",
    "            else:\n",
    "                file.write(\"\\n has_word({},{}_{}).\".format(sign_name(path), sign_name(path), i))\n",
    "                n , com =commonCharacterCount('STOP', item)\n",
    "                #print(item)\n",
    "                #print(n)\n",
    "                if n>2:\n",
    "                    #file.write(\"\\n nearly_match_letters({}_{}, {}).\".format(sign_name(path), i,  list('stop')))\n",
    "                    file.write(\"\\n nearly_match_letters({}_{}, {}).\".format(sign_name(path), i, 'stop'))\n",
    "\n",
    "                # write each item on a new line\n",
    "                file.write(\"\\n has_letters({}_{},{}).\".format(sign_name(path), i,list(item.lower())))\n",
    "\n",
    "                if item.isupper():\n",
    "                    file.write(\"\\n font_case({}_{}, uppercase).\".format(sign_name(path), i))\n",
    "                elif item.islower():\n",
    "                    file.write(\"\\n font_case({}_{}, lowercase).\".format(sign_name(path), i))\n",
    "                else:\n",
    "                    file.write(\"\\n font_case({}_{}, mixed).\".format(sign_name(path), i))\n",
    "\n",
    "    #print('Done')\n",
    "    file.close()\n",
    "    \n",
    "    \n",
    "def commonCharacterCount(s1, s2):\n",
    "    a=list(set(s1)&set(s2))\n",
    "    return(len(a), a)        \n",
    "\n",
    "\n",
    "def nearly_match(item):\n",
    "    List = [ 'down', 'stop', 'work', 'enter', 'not', 'give', 'way']\n",
    "    #print('item=', item)\n",
    "    m = len(item)\n",
    "    OUT = []\n",
    "    if m!= 0:\n",
    "        item = item.lower()\n",
    "        print('item=', item)\n",
    "        print('item=', item)\n",
    "        for word in List:\n",
    "            s = len(word)\n",
    "            n , com =commonCharacterCount(word, item )\n",
    "            print(n/max(m,s))\n",
    "            if n/max(m,s)>0.5:\n",
    "                OUT.append(word)\n",
    "\n",
    "    print(\"finalout=\", OUT)\n",
    "    return OUT\n",
    "\n",
    "\n",
    "# A text file is created and flushed\n",
    "def has_word(item, path, Extract_path):\n",
    "    items = list(dict.fromkeys(item))\n",
    "    print('items=', items)\n",
    "    with open(Extract_path, \"a+\") as file:\n",
    "        for idx, item in enumerate(items):\n",
    "            i = idx+1\n",
    "            if item.isdigit():\n",
    "                file.write(\"\\n has_number({},{}_{}).\".format(sign_name(path), sign_name(path), i))\n",
    "                file.write(\"\\n has_digits({}_{},{}).\".format(sign_name(path), i, item))\n",
    "            else:\n",
    "                \n",
    "                #corrected = spell.correction(item)\n",
    "                print('item=', item)\n",
    "                word = Word(item)\n",
    "                corrected = word.correct()\n",
    "                print('corrected=', corrected)\n",
    "\n",
    "                word = nearly_match(item)\n",
    "\n",
    "                print('word=', word)\n",
    "                word = ''.join(word)\n",
    "                print('word=', word)\n",
    "                #if word == 'NONE':\n",
    "                #    file.write(\"\\n Other_letters({}_{}, {}).\".format(sign_name(path), i, word))\n",
    "                #else:\n",
    "                if len(word) > 1:\n",
    "                    file.write(\"\\n has_word({},{}_{}).\".format(sign_name(path), sign_name(path), i))\n",
    "                    file.write(\"\\n nearly_match_letters({}_{}, {}).\".format(sign_name(path), i, word))\n",
    "                    #if item.isupper():\n",
    "                    #    file.write(\"\\n font_case({}_{}, uppercase).\".format(sign_name(path), i))\n",
    "                    #elif item.islower():\n",
    "                    #    file.write(\"\\n font_case({}_{}, lowercase).\".format(sign_name(path), i))\n",
    "                    #else:\n",
    "                    #    file.write(\"\\n font_case({}_{}, mixed).\".format(sign_name(path), i))\n",
    "\n",
    "    #print('Done')\n",
    "    file.close()\n",
    "    \n",
    "    \n",
    "def recognize_text_(image):\n",
    "    '''loads an image and recognizes text.'''\n",
    "    reader = easyocr.Reader(['en'])\n",
    "    #image= remove_noise_T(image)\n",
    "\n",
    "    result = reader.readtext(image, detail=1, paragraph=False)\n",
    "    texts = []\n",
    "    for (bbox, text, prob) in result:\n",
    "        if prob >= 0.2:\n",
    "            # display \n",
    "            #print(f'Detected text: {text} (Probability: {prob:.2f})')\n",
    "            texts.append(text)\n",
    "    return texts\n",
    "            \n",
    "        \n",
    "    \n",
    "def recognize_text__(image):\n",
    "    '''loads an image and recognizes text.'''\n",
    "    reader = easyocr.Reader(['en'])\n",
    "    #image= remove_noise_T(image)\n",
    "\n",
    "    result = reader.readtext(image, detail=1, paragraph=False)\n",
    "    result1= reader.readtext(getcolormask('red', image), detail=1, paragraph=False)\n",
    "    result2= reader.readtext(getcolormask('white', image), detail=1, paragraph=False)\n",
    "\n",
    "    #result3= reader.readtext(getcolormask('black', image), detail=1, paragraph=False)\n",
    "    print('result=',result)\n",
    "    print('result1=',result1)\n",
    "    print('result2=',result2)\n",
    "    \n",
    "\n",
    "    texts = []\n",
    "    for (bbox, text, prob) in result:\n",
    "        getVals = list([val for val in text if val.isalpha() or val.isnumeric()])\n",
    "        text = \"\".join(getVals)\n",
    "        if prob >= 0.1 and text is not None:\n",
    "            # display \n",
    "            #print(f'Detected text: {text} (Probability: {prob:.2f})')\n",
    "            texts.append(text)\n",
    "    for (bbox, text, prob) in result1:\n",
    "        getVals = list([val for val in text if val.isalpha() or val.isnumeric()])\n",
    "        text = \"\".join(getVals)\n",
    "        if prob >= 0.1 and text is not None:\n",
    "            # display \n",
    "            #print(f'Detected text: {text} (Probability: {prob:.2f})')\n",
    "            texts.append(text)\n",
    "\n",
    "    for (bbox, text, prob) in result2:\n",
    "        getVals = list([val for val in text if val.isalpha() or val.isnumeric()])\n",
    "        text = \"\".join(getVals)\n",
    "        if prob >= 0.1 and text is not None:\n",
    "            # display \n",
    "            #print(f'Detected text: {text} (Probability: {prob:.2f})')\n",
    "            texts.append(text)\n",
    "\n",
    "    texts = list( dict.fromkeys(texts)) \n",
    "    return texts\n",
    "\n",
    "\n",
    "def recognize_text__(image):\n",
    "    '''loads an image and recognizes text.'''\n",
    "    img = image.copy()\n",
    "    img= remove_noise_T(img)\n",
    "    custom_config = r'--oem 3 --psm 13'\n",
    "    text = pytesseract.image_to_string(img, config=custom_config)\n",
    "    print(text)\n",
    "    return text\n",
    "\n",
    "def recognize_text(image):\n",
    "    '''loads an image and recognizes text.'''\n",
    "    reader = easyocr.Reader(['en'])\n",
    "    #image= remove_noise_T(image)\n",
    "\n",
    "    result = reader.readtext(image, detail=1, paragraph=False)\n",
    "    texts = []\n",
    "    for (bbox, text, prob) in result:\n",
    "        getVals = list([val for val in text if val.isalpha() or val.isnumeric()])\n",
    "        text = \"\".join(getVals)\n",
    "        if prob >= 0.1 and text is not None:\n",
    "            # display \n",
    "            #print(f'Detected text: {text} (Probability: {prob:.2f})')\n",
    "            texts.append(text)\n",
    "    texts = list( dict.fromkeys(texts)) \n",
    "    return texts\n",
    "\n",
    "def recognize_text_1(image):\n",
    "    '''loads an image and recognizes text.'''\n",
    "    img = image.copy()\n",
    "    img = get_contours(img)\n",
    "    smoothened = get_smoothened(contours)\n",
    "    stencil  = np.zeros(image.shape[:-1]).astype(np.uint8)\n",
    "    stencil[:] = 160\n",
    "\n",
    "        # Overlay the smoothed contours on the original image\n",
    "    cv2.drawContours(stencil, smoothened, -1, (255,0,255), thickness=cv2.FILLED)\n",
    "\n",
    "    text = pytesseract.image_to_string(stencil, config='--psm 13')\n",
    "    print(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#get colour mask\n",
    "def getcolormask(color, image):  \n",
    "    if color == 'red':\n",
    "        #lower_bound = np.array([160,50,50])\n",
    "        #upper_bound = np.array([180,255,255])\n",
    "        lower_bound_red = np.array([130,20,70])\n",
    "        upper_bound_red = np.array([180,255,255])\n",
    "        lower_bound_orange = np.array([0, 70, 25])\n",
    "        upper_bound_orange = np.array([25, 255, 255])\n",
    "        mask_red = cv2.inRange(get_hsv(image), lower_bound_red, upper_bound_red)\n",
    "        mask_orange = cv2.inRange(get_hsv(image), lower_bound_orange, upper_bound_orange)\n",
    "        mask = mask_orange + mask_red\n",
    "        \n",
    "\n",
    "\n",
    "    elif color == 'green':\n",
    "        lower_bound = np.array([50, 20, 20])   \n",
    "        upper_bound = np.array([100, 255, 255])\n",
    "        mask = cv2.inRange(get_hsv(image), lower_bound, upper_bound)\n",
    "\n",
    "    elif color == 'blue':\n",
    "        #lower_bound = np.array([108,50,38])\n",
    "        #upper_bound = np.array([120,255,255])\n",
    "        lower_bound = np.array([100,150,0])\n",
    "        upper_bound = np.array([140,255,255])\n",
    "        mask = cv2.inRange(get_hsv(image), lower_bound, upper_bound)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    elif color == 'black':\n",
    "        lower_bound = np.array([0, 0, 0])\n",
    "        upper_bound = np.array([[180, 255, 40]]) \n",
    "        mask = cv2.inRange(get_hsv(image), lower_bound, upper_bound)\n",
    "\n",
    "    elif color == 'white':\n",
    "        lower_bound = np.array([0,0,168])\n",
    "        upper_bound = np.array([172,111,255])\n",
    "        #lower_bound = np.array([0, 0, 10])\n",
    "        #upper_bound = np.array([255, 120, 255])\n",
    "        mask = cv2.inRange(get_hsv(image), lower_bound, upper_bound)\n",
    "\n",
    "    elif color == 'yellow':\n",
    "        lower_bound = np.array([20, 80, 80])\n",
    "        upper_bound = np.array([30, 255, 255])\n",
    "        mask = cv2.inRange(get_hsv(image), lower_bound, upper_bound)\n",
    "\n",
    "    mask = post_process(mask)\n",
    "    return mask\n",
    "\n",
    "\n",
    " \n",
    "    \n",
    "def get_color(image):    \n",
    "    max_area = get_max_area(image)\n",
    "\n",
    "    colors_present =[]\n",
    "    contour_list = []\n",
    "    for color in colors_list:\n",
    "        mask = getcolormask(color , image)\n",
    "\n",
    "        if cv2.countNonZero(mask) > min_area:\n",
    "\n",
    "            contours, hierarchy = cv2.findContours(mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "            if len(contours)>2:\n",
    "                #print(color)\n",
    "                colors_present.append(color)\n",
    "            else:\n",
    "                cnt_max = max(contours, key = cv2.contourArea)\n",
    "                area = cv2.contourArea(cnt_max) \n",
    "                #print(\"{},{}\".format(color, area))\n",
    "                if (area > min_area) and (area < max_area ) :\n",
    "                    colors_present.append(color)\n",
    "    colors_present = list(dict.fromkeys(colors_present))\n",
    "    return colors_present\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# find contours via color mask\n",
    "def get_contours(image):\n",
    "    contour_list = []\n",
    "    for color in colors_list:\n",
    "        mask = getcolormask(color , image)\n",
    "        if cv2.countNonZero(mask) > min_area:\n",
    "            contours, hierarchy = cv2.findContours(mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "            for cnt in contours: \n",
    "                if cv2.contourArea(cnt, True)>0:    #Consider only clockwise contours\n",
    "                    contour_list.append(cnt)\n",
    "#    cnt_max = max(contour_list, key = cv2.contourArea)\n",
    "#    contour_list.remove(cnt_max)\n",
    "#    cv2.drawContours(image, contour_list,  -1, (0,255,0), 8)\n",
    "#    print(len(contour_list))\n",
    "    return contour_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# find biggest contours\n",
    "def get_external_contour(image):    \n",
    "    max_area = get_max_area(image)\n",
    "\n",
    "    contours = get_contours(image)\n",
    "    cnt = max(contours, key = cv2.contourArea)\n",
    "    area = cv2.contourArea(cnt)\n",
    "    if (area > min_area) and (area < max_area ):\n",
    "        cnt_max=cnt\n",
    "    else:\n",
    "        contours.remove(cnt)\n",
    "        cnt_max = max(contours, key = cv2.contourArea)\n",
    "    \n",
    "    #cv2.drawContours(image, cnt_max,  -1, (255,0,0), 5)\n",
    "    return cnt_max\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_external_shape(image):\n",
    " #   remove_bg(image)\n",
    "    cnt = get_external_contour(image) \n",
    "    #cv2.drawContours(image, cnt,  -1, (0,255,0), 2)\n",
    "    approx = cv2.approxPolyDP(cnt, alpha*cv2.arcLength(cnt, True), True)\n",
    "    #print(len(approx))\n",
    "    (x, y, w, h) = cv2.boundingRect(approx)\n",
    "    ar = w / float(h)\n",
    "    #print(len(approx))\n",
    "    if len(approx) == 3 : #and cv2.isContourConvex(cnt)\n",
    "        shape = \"triangle\"\n",
    "    elif len(approx) == 4 :\n",
    "        shape = \"rectangle\"\n",
    "    elif len(approx) == 5 :\n",
    "        shape = \"pentagon\"\n",
    "    elif len(approx) == 6 :\n",
    "        shape = \"hexagon\"\n",
    "    elif len(approx) == 8:\n",
    "        if ar >= 0.95 and ar <= 1.05 :\n",
    "            shape = \"octagon\"\n",
    "        else:\n",
    "            shape = \"other\"\n",
    "    elif 14 < len(approx) < 20 and ar >= 0.95 and ar <= 1.05 :\n",
    "        shape = \"circle\"\n",
    "    else:\n",
    "        shape = \"other\"\n",
    "    return shape\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def get_shape(image):\n",
    "    max_area = get_max_area(image)\n",
    "    \n",
    "    shape_list = [] \n",
    "    contours = get_contours(image)\n",
    "    cv2.drawContours(image, contours,  -1, (0,255,255), 12)\n",
    "    \n",
    "#    print(len(contours))\n",
    "\n",
    "    #print(len(contours))\n",
    "#    cnt_max = max(contours, key = cv2.contourArea)\n",
    "#    contours.remove(cnt_max)\n",
    "\n",
    "#    print(len(contours))\n",
    "\n",
    "#    cv2.drawContours(image, contours,  -1, (0,255,0), 3)\n",
    "\n",
    "    for cnt in contours:\n",
    "\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if (area > min_area) and (area < max_area ) :\n",
    "            approx = cv2.approxPolyDP(cnt, alpha*cv2.arcLength(cnt, True), True)\n",
    "            (x, y, w, h) = cv2.boundingRect(approx)\n",
    "\n",
    "            ar = w / float(h)\n",
    "            #print(len(approx))\n",
    "            if len(approx) == 3 :\n",
    "                shape = \"triangle\"\n",
    "            elif len(approx) == 4 :\n",
    "                 shape = \"rectangle\"\n",
    "            elif len(approx) == 5 :\n",
    "                shape = \"pentagon\"\n",
    "            elif len(approx) == 6 :\n",
    "                shape = \"hexagon\"\n",
    "            elif len(approx) == 8:\n",
    "                if ar >= 0.95 and ar <= 1.05 :\n",
    "                    shape = \"octagon\"\n",
    "                else:\n",
    "                    #print('T')\n",
    "                    shape = \"other\"\n",
    "            elif 14 < len(approx) < 20:\n",
    "                if ar >= 0.95 and ar <= 1.05 :\n",
    "                    shape = \"circle\" \n",
    "                    cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "                else:\n",
    "                    shape = \"other\" \n",
    "                    #print(ar)\n",
    "#                    cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            else:\n",
    "                shape = \"other\"\n",
    "                #print(len(approx))\n",
    "#                cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,255),4)\n",
    "                #cv2.drawContours(image, approx,  -1, (0,255,0), 13)\n",
    "            shape_list.append(shape)\n",
    "#ÃŸ    my_dict = {i:shape_list.count(i) for i in shape_list}\n",
    "    shape_list = list(dict.fromkeys(shape_list))        \n",
    "    return shape_list\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def remove_bg_(image):\n",
    "#    image = remove_noise(image)\n",
    "    image = remove(image) \n",
    "    image = cv2.cvtColor(np.array(image), cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "    image = image.copy()\n",
    "\n",
    "    if len(image.shape) > 2 and image.shape[2] == 4:\n",
    "        image = image[:, :, :3]\n",
    "    contour = [get_external_contour(image)]\n",
    "    fill_color = [205,192,176] # any BGR color value to fill with\n",
    "    mask_value = 255            # 1 channel white (can be any non-zero uint8 value)\n",
    "    stencil  = np.zeros(image.shape[:-1]).astype(np.uint8)\n",
    "    cv2.fillPoly(stencil, contour, mask_value)\n",
    "    sel      = stencil != mask_value # select everything that is not mask_value\n",
    "    image[sel] = fill_color            # and fill it with fill_color\n",
    "\n",
    "    return image\n",
    "\n",
    "def remove_bg(image):\n",
    "    image = remove(image) \n",
    "    image = cv2.cvtColor(np.array(image), cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "    return cv2.medianBlur(image,5)\n",
    "\n",
    "#cv2.drawContours(img, contours,  -1, (255,0,0), 5)\n",
    "\n",
    "# objects = car, bike, arrow, man, animal, exclamation, bump, snowflake\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "def white_bg(image):\n",
    "    tmp = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)   ## Convert image to image gray\n",
    "    _, alpha = cv2.threshold(tmp, 0, 255, cv2.THRESH_BINARY)  # Applying thresholding technique\n",
    "    b, g, r = cv2.split(image) # Using cv2.split() to split channels of coloured image\n",
    "    rgba = [b, g, r, alpha] # Making list of Red, Green, Blue Channels and alpha\n",
    "    dst = cv2.merge(rgba, 4) # Using cv2.merge() to merge rgba into a coloured/multi-channeled image\n",
    "    plt.imshow(dst)\n",
    "    #cv2.imwrite(\"gfg_white.png\", dst) # Writing and saving to a new image\n",
    "    return dst\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_matchshape(image):\n",
    "    objects_list = []\n",
    "    contours = get_contours(image)\n",
    "    for cnt in contours:\n",
    "        for shape in objects:\n",
    "            if cv2.matchShapes(cnt,shape,1,0.0)>0.05:\n",
    "                objects_list.append(shape)\n",
    "    return(objects_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "# noise removal canny edge\n",
    "def remove_noise(image):\n",
    "    image = cv2.cvtColor(np.array(image), cv2.COLOR_BGRA2BGR)\n",
    "    bilateral_filtered_img = cv2.bilateralFilter(image, 5, 175, 175)\n",
    "    return cv2.Canny(bilateral_filtered_img, 70, 200)\n",
    "\n",
    "def remove_noise_(image):\n",
    "    image = cv2.cvtColor(np.array(image), cv2.COLOR_BGRA2BGR)\n",
    "    bilateral_filtered_img = cv2.bilateralFilter(image, 5, 175, 175)\n",
    "    edges = cv2.Canny(bilateral_filtered_img, 70, 200)\n",
    "#    lines = cv2.HoughLinesP(edges,1,np.pi/180,100,minLineLength,maxLineGap)\n",
    "    lines = cv2.HoughLinesP(edges,rho = 1,theta = 1*np.pi/180,threshold = 100,minLineLength = 100,maxLineGap = 5)\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        cv2.line(image, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
    "    return(image)\n",
    "\n",
    "def remove_noise_T(image):\n",
    "    image = cv2.cvtColor(np.array(image), cv2.COLOR_BGRA2BGR)\n",
    "    bilateral_filtered_img = cv2.bilateralFilter(image, 5, 175, 175)\n",
    "    blur = cv2.medianBlur(bilateral_filtered_img, 5) \n",
    "    return thresholding(blur)\n",
    "\n",
    "\n",
    "def remove_noise_Text(image):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    gray, img_bin = cv2.threshold(gray,128,255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    gray = cv2.bitwise_not(img_bin)\n",
    "    img = cv2.erode(gray, kernel, iterations=1)\n",
    "    img = cv2.dilate(img, kernel, iterations=1)\n",
    "    return(img)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# convert to hsv\n",
    "def get_hsv(image):\n",
    "    blur = cv2.medianBlur(image, 5)  #applying median filter to remove noice\n",
    "    #blur = cv2.GaussianBlur(image, (5,5), 0)\n",
    "    return cv2.cvtColor(blur,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "# noise removal\n",
    "def remove_noise2(image):\n",
    "    return cv2.medianBlur(image,5)\n",
    " \n",
    "#thresholding\n",
    "def thresholding(image):\n",
    "    gray= cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    return cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "#dilation\n",
    "def dilate(image):\n",
    "#    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.dilate(image, kernel, iterations = 1)\n",
    "    \n",
    "#erosion\n",
    "def erode(image):\n",
    "#    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.erode(image, kernel, iterations = 1)\n",
    "\n",
    "#opening - erosion followed by dilation\n",
    "def opening(image):\n",
    "#    kernel = np.ones((5,5),np.uint8)\n",
    "    opening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "    return remove_noise(opening)\n",
    "\n",
    "def gradient(image):\n",
    "#    kernel = np.ones((5,5),np.uint8)\n",
    "    gradient = cv2.morphologyEx(image, cv2.MORPH_GRADIENT, kernel)\n",
    "    return remove_noise(gradient)\n",
    "\n",
    "def approximate_contours(contours):\n",
    "    result = []\n",
    "    for x in contours:\n",
    "        epsilon = 0.005 * cv2.arcLength(x, True)\n",
    "        approx = cv2.approxPolyDP(x, epsilon, True)\n",
    "        result.append(approx)\n",
    "    return result\n",
    "\n",
    "#canny edge detection\n",
    "def canny(image):\n",
    "    return cv2.Canny(image, 100, 200)\n",
    "\n",
    "#skew correction\n",
    "def deskew(image):\n",
    "    coords = np.column_stack(np.where(image > 0))\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated\n",
    "\n",
    "def post_process(mask):\n",
    "    \"\"\"\n",
    "    Post Process the mask for a smooth boundary by applying Morphological Operations\n",
    "    Research based on paper: https://www.sciencedirect.com/science/article/pii/S2352914821000757\n",
    "    args:\n",
    "        mask: Binary Numpy Mask\n",
    "    \"\"\"\n",
    "    #closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    mask = cv2.GaussianBlur(mask, (5, 5), sigmaX=2, sigmaY=2, borderType=cv2.BORDER_DEFAULT)\n",
    "#    mask = np.where(mask < 127, 0, 255).astype(np.uint8)  # convert again to binary\n",
    "    #bilateral_filtered_img = cv2.bilateralFilter(mask, 9, 175, 175)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "\n",
    "def get_circle(image):\n",
    "    circles = cv2.HoughCircles(remove_noise(image), cv2.HOUGH_GRADIENT, 1.2, image.size/3000)\n",
    "    if circles is not None:\n",
    "        circles = np.uint16(np.around(circles))\n",
    "    return circles \n",
    "\n",
    "def get_line(image):\n",
    "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray,50,120)\n",
    "    minLineLength = 20\n",
    "    maxLineGap = 5\n",
    "    lines = cv2.HoughLinesP(edges,1,np.pi/180,100,minLineLength,maxLineGap)\n",
    "    for x1,y1,x2,y2 in lines[0]:\n",
    "        cv2.line(image,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "    return(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Extract_features(path):\n",
    "    \n",
    "    write_name(path, Extract_path)\n",
    "    img = cv2.imread(path)    \n",
    "    img = remove_bg(img)\n",
    "    image = cv2.cvtColor(np.array(img), cv2.COLOR_BGRA2BGR)\n",
    "    image = cv2.bilateralFilter(image, 5, 175, 175)\n",
    "    colors_present = get_color(image)\n",
    "    has_color(colors_present, path, Extract_path)        \n",
    "\n",
    "    result1 = recognize_text(remove_noise_T(img))\n",
    "    result1 = [name.lower() for name in result1]\n",
    "\n",
    "    result2 = recognize_text(img)\n",
    "    result2 = [name.lower() for name in result2]\n",
    "\n",
    "    result  = list(dict.fromkeys(result1 + result2))\n",
    "    print('result1=', result1)\n",
    "\n",
    "    print('result2=', result2)\n",
    "    print('result=', result)\n",
    "    has_word(result, path, Extract_path)\n",
    "\n",
    "    shape = get_shape(image)\n",
    "    has_shape(shape, path, Extract_path)\n",
    "\n",
    "    #external_shape = get_external_shape(img)\n",
    "    #has_external_shape(external_shape, path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_smoothened(contours):\n",
    "    smoothened = []\n",
    "    for contour in contours:\n",
    "        x,y = contour.T\n",
    "        # Convert from numpy arrays to normal arrays\n",
    "        x = x.tolist()[0]\n",
    "        y = y.tolist()[0]\n",
    "        # https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.interpolate.splprep.html\n",
    "        tck, u = splprep([x,y], u=None, s=1.0, per=1)\n",
    "        # https://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.linspace.html\n",
    "        u_new = np.linspace(u.min(), u.max(), 40)\n",
    "        # https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.interpolate.splev.html\n",
    "        x_new, y_new = splev(u_new, tck, der=0)\n",
    "        # Convert it back to numpy format for opencv to be able to display it\n",
    "        res_array = [[[int(i[0]), int(i[1])]] for i in zip(x_new,y_new)]\n",
    "        smoothened.append(np.asarray(res_array, dtype=np.int32))\n",
    "    return smoothened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity(contour):\n",
    "    object_list = []\n",
    "    for object in objects:\n",
    "        match = cv2.matchShapes(template_contour, c, 3, 0.0)\n",
    "        similarity = cv2.matchShapes(poly.reshape((poly.shape[0], 1, poly.shape[1])), contour, cv2.cv.CV_CONTOURS_MATCH_I2, 0)\n",
    "        if match < 0.15:\n",
    "            closest_contour = c\n",
    "        else:\n",
    "            closest_contour = [] \n",
    "        if similarity>.5:\n",
    "            object_list.append(object)\n",
    "    return object_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1= ['stop']\n",
      "result2= ['stop']\n",
      "result= ['stop']\n",
      "items= ['stop']\n",
      "item= stop\n",
      "corrected= stop\n",
      "item= stop\n",
      "item= stop\n",
      "0.25\n",
      "1.0\n",
      "0.25\n",
      "0.2\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "Train_5/Test/subtle/octnoise_10ft_0deg.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1= []\n",
      "result2= ['stop']\n",
      "result= ['stop']\n",
      "items= ['stop']\n",
      "item= stop\n",
      "corrected= stop\n",
      "item= stop\n",
      "item= stop\n",
      "0.25\n",
      "1.0\n",
      "0.25\n",
      "0.2\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "Train_5/Test/subtle/octnoise_10ft_15deg.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1= []\n",
      "result2= ['stop']\n",
      "result= ['stop']\n",
      "items= ['stop']\n",
      "item= stop\n",
      "corrected= stop\n",
      "item= stop\n",
      "item= stop\n",
      "0.25\n",
      "1.0\n",
      "0.25\n",
      "0.2\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "Train_5/Test/subtle/octnoise_10ft_30deg.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1= ['stop']\n",
      "result2= ['stop']\n",
      "result= ['stop']\n",
      "items= ['stop']\n",
      "item= stop\n",
      "corrected= stop\n",
      "item= stop\n",
      "item= stop\n",
      "0.25\n",
      "1.0\n",
      "0.25\n",
      "0.2\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "Train_5/Test/subtle/octnoise_15ft_0deg.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1= []\n",
      "result2= ['stopi']\n",
      "result= ['stopi']\n",
      "items= ['stopi']\n",
      "item= stopi\n",
      "corrected= stop\n",
      "item= stopi\n",
      "item= stopi\n",
      "0.2\n",
      "0.8\n",
      "0.2\n",
      "0.2\n",
      "0.4\n",
      "0.2\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "Train_5/Test/subtle/octnoise_15ft_15deg.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1= ['stqp']\n",
      "result2= ['stop']\n",
      "result= ['stqp', 'stop']\n",
      "items= ['stqp', 'stop']\n",
      "item= stqp\n",
      "corrected= step\n",
      "item= stqp\n",
      "item= stqp\n",
      "0.0\n",
      "0.75\n",
      "0.0\n",
      "0.2\n",
      "0.25\n",
      "0.0\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "item= stop\n",
      "corrected= stop\n",
      "item= stop\n",
      "item= stop\n",
      "0.25\n",
      "1.0\n",
      "0.25\n",
      "0.2\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "Train_5/Test/subtle/octnoise_20ft_0deg.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1= ['op']\n",
      "result2= ['stop']\n",
      "result= ['op', 'stop']\n",
      "items= ['op', 'stop']\n",
      "item= op\n",
      "corrected= op\n",
      "item= op\n",
      "item= op\n",
      "0.25\n",
      "0.5\n",
      "0.25\n",
      "0.0\n",
      "0.3333333333333333\n",
      "0.0\n",
      "0.0\n",
      "finalout= []\n",
      "word= []\n",
      "word= \n",
      "item= stop\n",
      "corrected= stop\n",
      "item= stop\n",
      "item= stop\n",
      "0.25\n",
      "1.0\n",
      "0.25\n",
      "0.2\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "Train_5/Test/subtle/octnoise_20ft_15deg.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1= ['stqpi']\n",
      "result2= ['stop']\n",
      "result= ['stqpi', 'stop']\n",
      "items= ['stqpi', 'stop']\n",
      "item= stqpi\n",
      "corrected= steps\n",
      "item= stqpi\n",
      "item= stqpi\n",
      "0.0\n",
      "0.6\n",
      "0.0\n",
      "0.2\n",
      "0.2\n",
      "0.2\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "item= stop\n",
      "corrected= stop\n",
      "item= stop\n",
      "item= stop\n",
      "0.25\n",
      "1.0\n",
      "0.25\n",
      "0.2\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "Train_5/Test/subtle/octnoise_25ft_0deg.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1= ['stqp']\n",
      "result2= ['stop']\n",
      "result= ['stqp', 'stop']\n",
      "items= ['stqp', 'stop']\n",
      "item= stqp\n",
      "corrected= step\n",
      "item= stqp\n",
      "item= stqp\n",
      "0.0\n",
      "0.75\n",
      "0.0\n",
      "0.2\n",
      "0.25\n",
      "0.0\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "item= stop\n",
      "corrected= stop\n",
      "item= stop\n",
      "item= stop\n",
      "0.25\n",
      "1.0\n",
      "0.25\n",
      "0.2\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "Train_5/Test/subtle/octnoise_30ft_0deg.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1= ['ctqp']\n",
      "result2= ['stop']\n",
      "result= ['ctqp', 'stop']\n",
      "items= ['ctqp', 'stop']\n",
      "item= ctqp\n",
      "corrected= step\n",
      "item= ctqp\n",
      "item= ctqp\n",
      "0.0\n",
      "0.5\n",
      "0.0\n",
      "0.2\n",
      "0.25\n",
      "0.0\n",
      "0.0\n",
      "finalout= []\n",
      "word= []\n",
      "word= \n",
      "item= stop\n",
      "corrected= stop\n",
      "item= stop\n",
      "item= stop\n",
      "0.25\n",
      "1.0\n",
      "0.25\n",
      "0.2\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "Train_5/Test/subtle/octnoise_40ft_0deg.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1= ['fop', '0']\n",
      "result2= ['istop']\n",
      "result= ['fop', '0', 'istop']\n",
      "items= ['fop', '0', 'istop']\n",
      "item= fop\n",
      "corrected= for\n",
      "item= fop\n",
      "item= fop\n",
      "0.25\n",
      "0.5\n",
      "0.25\n",
      "0.0\n",
      "0.3333333333333333\n",
      "0.0\n",
      "0.0\n",
      "finalout= []\n",
      "word= []\n",
      "word= \n",
      "item= istop\n",
      "corrected= stop\n",
      "item= istop\n",
      "item= istop\n",
      "0.2\n",
      "0.8\n",
      "0.2\n",
      "0.2\n",
      "0.4\n",
      "0.2\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "Train_5/Test/subtle/octnoise_5ft_0deg.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1= ['op']\n",
      "result2= ['stop']\n",
      "result= ['op', 'stop']\n",
      "items= ['op', 'stop']\n",
      "item= op\n",
      "corrected= op\n",
      "item= op\n",
      "item= op\n",
      "0.25\n",
      "0.5\n",
      "0.25\n",
      "0.0\n",
      "0.3333333333333333\n",
      "0.0\n",
      "0.0\n",
      "finalout= []\n",
      "word= []\n",
      "word= \n",
      "item= stop\n",
      "corrected= stop\n",
      "item= stop\n",
      "item= stop\n",
      "0.25\n",
      "1.0\n",
      "0.25\n",
      "0.2\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "Train_5/Test/subtle/octnoise_5ft_15deg.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1= []\n",
      "result2= ['stop']\n",
      "result= ['stop']\n",
      "items= ['stop']\n",
      "item= stop\n",
      "corrected= stop\n",
      "item= stop\n",
      "item= stop\n",
      "0.25\n",
      "1.0\n",
      "0.25\n",
      "0.2\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "Train_5/Test/subtle/octnoise_5ft_30deg.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1= []\n",
      "result2= ['stop']\n",
      "result= ['stop']\n",
      "items= ['stop']\n",
      "item= stop\n",
      "corrected= stop\n",
      "item= stop\n",
      "item= stop\n",
      "0.25\n",
      "1.0\n",
      "0.25\n",
      "0.2\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "Train_5/Test/subtle/octnoise_5ft_45deg.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1= []\n",
      "result2= ['topl']\n",
      "result= ['topl']\n",
      "items= ['topl']\n",
      "item= topl\n",
      "corrected= top\n",
      "item= topl\n",
      "item= topl\n",
      "0.25\n",
      "0.75\n",
      "0.25\n",
      "0.2\n",
      "0.5\n",
      "0.0\n",
      "0.0\n",
      "finalout= ['stop']\n",
      "word= ['stop']\n",
      "word= stop\n",
      "Train_5/Test/subtle/octnoise_5ft_60deg.jpg\n"
     ]
    }
   ],
   "source": [
    "#source_path = \"Train_5/Training\"\n",
    "\n",
    "source_path = \"Train_5/Training/*\"\n",
    "Extract_path = \"Train_5/Training/Training_BK.txt\"\n",
    "\n",
    "#source_path = \"Train_5/Test/subtle/*\"\n",
    "#Extract_path = \"Train_5/Test/subtle/bk_subtle.txt\"\n",
    "\n",
    "#source_path = \"Train_5/Test/LoveHate/*\"\n",
    "#Extract_path = \"Train_5/Test/LoveHate/bk_Love.txt\"\n",
    "\n",
    "#source_path = \"Train_5/Test/LoveHate/Angle/*\"\n",
    "#Extract_path = \"Train_5/Test/LoveHate/bk_Love_Angle.txt\"\n",
    "\n",
    "#source_path = \"Train_5/Test/BW Rectangles - GTSRB/*\"\n",
    "#Extract_path = \"Train_5/Test/BW Rectangles - GTSRB/bk_GTSRB.txt\"\n",
    "\n",
    "\n",
    "\n",
    "for filename in sorted(glob.iglob(source_path, recursive=True)):\n",
    "    if (filename.endswith(\".png\")) or (filename.endswith(\".jpeg\")) or (filename.endswith(\".jpg\")):\n",
    "        Extract_features(filename)\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = \"Train_5/Training\"\n",
    "\n",
    "Extract_path = \"Train_5/Training/background_knowledge.txt\"\n",
    "\n",
    "imdir = 'path/to/files/'\n",
    "ext = ['png', 'jpg', 'jpeg']    # Add image formats here\n",
    "\n",
    "try:\n",
    "    os.remove(Extract_path)\n",
    "except OSError:\n",
    "    pass\n",
    "#    results_file.write('hi\\n')\n",
    "with open(Extract_path, \"a+\") as file:\n",
    "    file.write(\"\\n \\n % In the name of Allah\")\n",
    "file.close()    \n",
    "    \n",
    "    \n",
    "files = []\n",
    "[files.extend(glob.glob(source_path + '*.' + e)) for e in ext]\n",
    "#print(files)\n",
    "\n",
    "#for filename in sorted(glob.iglob(source_path, recursive=True)):\n",
    "for filename in sorted(files):\n",
    "\n",
    "    Extract_features(filename)\n",
    "    print(filename)\n",
    "\n",
    "\n",
    "#for filename in sorted(glob.iglob(source_path, recursive=True)):\n",
    "#    Extract_features(filename)\n",
    "#    print(filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source_path = \"Train_5/Training/N9.jpeg\"\n",
    "\n",
    "#Extract_path = \"Train_5/Training/background_knowledge.txt\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "source_path = \"Train_5/Test/subtle\"\n",
    "Extract_path = \"Train_5/Test/subtle/bk_subtle.txt\"\n",
    "\n",
    "\n",
    "\n",
    "for filename in sorted(glob.iglob(source_path, recursive=True)):\n",
    "    Extract_features(filename)\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([[66, 361], [1299, 361], [1299, 950], [66, 950]], 'STOP', 0.8394888639450073)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#path = \"Train_4/P5.jpg\"\n",
    "path = \"Train_5/Test/BW Rectangles - GTSRB/pseudogerman-largebandwrectangles-basement_05ft_0deg.jpg\"\n",
    "\n",
    "\n",
    "img = cv2.imread(path)    \n",
    "img = remove_bg(img)\n",
    "#img = cv2.cvtColor(np.array(img), cv2.COLOR_BGRA2BGR)\n",
    "#img = cv2.bilateralFilter(img, 5, 175, 175)\n",
    "#img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "mask = getcolormask('blue' , img)\n",
    "\n",
    "\n",
    "\n",
    "reader = easyocr.Reader(['en'])\n",
    "img= remove_noise_T(img)\n",
    "plt.imshow(img)\n",
    "\n",
    "result = reader.readtext(img, detail=1, paragraph=False)\n",
    "#result = recognize_text(img)\n",
    "#word = Word(result)\n",
    "#corrected = word.correct()\n",
    "#word = nearly_match(result[0])\n",
    "print(result)\n",
    "#plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Train/Train_Neg_8.png\"\n",
    "img = cv2.imread(path)\n",
    "img = remove_bg(img)\n",
    "\n",
    "\n",
    "\n",
    "contour_list = []\n",
    "mask = getcolormask('green' , image)\n",
    "if cv2.countNonZero(mask) > min_area:\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "    smoothened = get_smoothened(contours)\n",
    "    cv2.drawContours(img, contours, -1, (255,0,255), thickness=12)\n",
    "    for cnt in contours: \n",
    "        if cv2.contourArea(cnt, True)>0:    #Consider only clockwise contours\n",
    "            contour_list.append(cnt)\n",
    "\n",
    "\n",
    "\n",
    "#cv2.drawContours(img, contour_list, -1, (255,0,255), thickness=12)\n",
    "\n",
    "\n",
    "#print(get_color(img))\n",
    "#shape = get_shape(img)\n",
    "#print(shape)\n",
    "#img= remove_noise_T(img)\n",
    "#contours, hierarchy = cv2.findContours(img, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "#smoothened = get_smoothened(contours)\n",
    "#mask = getcolormask('green' , img)\n",
    "#contours, hierarchy = cv2.findContours(mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "print(len(contours))\n",
    "print(len(contour_list))\n",
    "                                       \n",
    "                                       #cv2.drawContours(img, smoothened,  -1, (255,0,0), 5)\n",
    "#image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "plt.imshow(img)\n",
    "\n",
    "#contours = get_contours(img)\n",
    "#cnt_max = max(contours, key = cv2.contourArea)\n",
    "#contours.remove(cnt_max)\n",
    "#stencil  = np.zeros(image.shape[:-1]).astype(np.uint8)\n",
    "#stencil[:] = 160\n",
    "\n",
    "\n",
    "#smoothened = get_smoothened(contours)\n",
    "\n",
    "\n",
    "# Overlay the smoothed contours on the original image\n",
    "#cv2.drawContours(img, smoothened, -1, (255,0,255), thickness=cv2.FILLED)\n",
    "\n",
    "#cv2.imwrite('remove_noise_T.png',img) \n",
    "#text = pytesseract.image_to_string(img, config='--psm 13')\n",
    "#text = reader.readtext(image, detail=1, paragraph=False)\n",
    "#print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Train_4/tp5.png\"\n",
    "img = cv2.imread(path)\n",
    "img = remove_bg(img)\n",
    "#mask = getcolormask('red' , image)\n",
    "\n",
    "    #image= remove_noise_T(image)\n",
    "\n",
    "#plt.imshow(img)\n",
    "#colors_present = get_color(img)\n",
    "#print(colors_present)\n",
    "#mask = getcolormask('red' , img)\n",
    "\n",
    "result = recognize_text(img)\n",
    "#result = recognize_text(img)\n",
    "#reader = easyocr.Reader(['en'])\n",
    "\n",
    "#result1 =reader.readtext(img, detail=1, paragraph=False)\n",
    "for item in result:\n",
    "    corrected = spell.correction(item)\n",
    "print(corrected)\n",
    "plt.imshow(img)\n",
    "print(spell.correction('STOPL'))\n",
    "\n",
    "            \n",
    "#has_word(result, path)\n",
    "#string = 'STOP'\n",
    "#string = list(string)\n",
    "#string = string.split(None, 3)\n",
    "#print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#path = \"attac-stop.png\"\n",
    "path = \"threshold10.png\"\n",
    "\n",
    "\n",
    "img = cv2.imread(path)\n",
    "img = remove(img)\n",
    "img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "contours = get_contours(img)\n",
    "#cnt_max = max(contours, key = cv2.contourArea)\n",
    "#contours.remove(cnt_max)\n",
    "\n",
    "stencil  = np.zeros(image.shape[:-1]).astype(np.uint8)\n",
    "stencil[:] = 160\n",
    "\n",
    "\n",
    "smoothened = get_smoothened(contours)\n",
    "\n",
    "\n",
    "# Overlay the smoothed contours on the original image\n",
    "cv2.drawContours(stencil, smoothened, -1, (255,255,255), thickness=cv2.FILLED)\n",
    "cv2.imwrite('Smooth10.png',stencil) \n",
    "\n",
    "plt.imshow(stencil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"uw17-square.jpg\"\n",
    "#path = \"stop-sign.jpg\"\n",
    "path = \"threshold10.png\"\n",
    "img = cv2.imread(path)\n",
    "#max_area = get_max_area(img)\n",
    "#img = remove(img)\n",
    "reader = easyocr.Reader(['en'])\n",
    "result = reader.readtext(image, detail=1, paragraph=False)\n",
    "#(bbox, text, prob) \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t80u-iAl8BVU",
    "outputId": "6540fee0-a400-4649-d9c4-a314d98623b9"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#img = cv2.imread('p-300x168.png')\n",
    "\n",
    "img = cv2.imread('Smooth10.png')\n",
    "image = cv2.cvtColor(np.array(img), cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "#image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "text = pytesseract.image_to_string(img, config='--psm 13')\n",
    "#d = pytesseract.image_to_string(image, output_type=Output.DICT)\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"attac-stop.png\"\n",
    "path = \"uw17-square.jpg\"\n",
    "alpha = .006\n",
    "#path = \"stop-sign.jpg\"\n",
    "img = cv2.imread(path)\n",
    "#max_area = get_max_area(img)\n",
    "#write_name(path)\n",
    "img = remove(img)\n",
    "img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "stencil  = np.zeros(image.shape[:-1]).astype(np.uint8)\n",
    "stencil[:] = 160\n",
    "\n",
    "contours = get_contours(img)\n",
    "cnt_max = max(contours, key = cv2.contourArea)\n",
    "contours.remove(cnt_max)\n",
    "\n",
    "\n",
    "for cnt in contours:\n",
    "    approx = cv2.approxPolyDP(cnt, alpha*cv2.arcLength(cnt, True), True)\n",
    "    #cv2.drawContours(image, approx, -1, (255, 255, 0), thickness=cv2.FILLED)\n",
    "    #cv2.fillPoly(img, approx, (255,0,255))\n",
    "    cv2.drawContours(stencil, [approx], 0, (0, 255, 255), -1)\n",
    "\n",
    "\n",
    "#cv2.drawContours(img, contours,  -1, (255,0,0), thickness=cv2.FILLED)  \n",
    "cv2.imwrite('cont.jpg',stencil) \n",
    "\n",
    "#dst = cv2.fastNlMeansDenoisingColored(img, None,10,10,7,21)\n",
    "\n",
    "\n",
    "\n",
    "#colors_present, shape_list, cnt_max = get_shape(image)\n",
    "#lines = cv2.HoughLinesP(remove_noise(image,rho = 1,theta = 1*np.pi/180,threshold = 100,minLineLength = 100,maxLineGap = 5)\n",
    "                                                \n",
    "#for line in lines:\n",
    "#    x1, y1, x2, y2 = line[0]\n",
    "#    cv2.line(image, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
    "\n",
    "#image = remove_noise(image)\n",
    "#lower_bound = np.array([107,50,60])\n",
    "#upper_bound = np.array([110,255,255])\n",
    "\n",
    "#mask = cv2.inRange(get_hsv(image), lower_bound, upper_bound)      \n",
    "#mask = getcolormask(\"red\", image)\n",
    "#contours, hierarchy = cv2.findContours(mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "#contours = get_contours(image)\n",
    "#min_area = 5000\n",
    "#contours_list = []\n",
    "#for cnt in contours:\n",
    "#    area = cv2.contourArea(cnt)\n",
    "#    print(area)\n",
    "#    if area > min_area and area<image.size/3.2:\n",
    "#        contours_list.append(cnt)\n",
    "\n",
    "#fill_color = [255,255,255] # any BGR color value to fill with\n",
    "#mask_value = 255            # 1 channel white (can be any non-zero uint8 value)\n",
    "#stencil  = np.zeros(image.shape[:-1]).astype(np.uint8)\n",
    "#stencil[:] = 160\n",
    "\n",
    "#cv2.fillPoly(stencil, contours_list, fill_color)\n",
    "\n",
    "\n",
    "#fin = cv2.bitwise_and(stencil, stencil, mask = maskred)\n",
    "#cv2.fillPoly(stencil, contours_list, mask_value)\n",
    "#sel      = stencil != mask_value # select everything that is not mask_value\n",
    "#image[sel] = fill_color            # and fill it with fill_color\n",
    "\n",
    "#mask = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel) \n",
    "#cnts, hier = cv2.findContours(image, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "#mx = max(cnts, key = cv2.contourArea)\n",
    "##cv2.drawContours(image, contours_list,  -1, (255,0,255), thickness=cv2.FILLED)\n",
    "\n",
    "#cv2.imwrite('cont.jpg',image) \n",
    "#print(len(cnts))\n",
    "#image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(stencil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reader = easyocr.Reader(['en'])\n",
    "result = reader.readtext(maskred, detail=1, paragraph=False)\n",
    "#(bbox, text, prob) \n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "colors_present = get_color(img)\n",
    "has_color(colors_present, path)        \n",
    "print(colors_present) \n",
    "\n",
    "result = recognize_text(stencil)\n",
    "has_word(result, path)\n",
    "print(result)\n",
    "\n",
    "#colors_present, shape, cnt_max = get_shape(img)\n",
    "shape = get_shape(img)\n",
    "\n",
    "has_shape(shape, path)\n",
    "print(shape)\n",
    "\n",
    "external_shape = get_external_shape(img)\n",
    "has_external_shape(external_shape, path)\n",
    "print(external_shape)\n",
    "\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "acoZAyLKW8ss",
    "outputId": "c4d8a97b-3ce3-4649-9226-784ca6650f98"
   },
   "outputs": [],
   "source": [
    "#img = cv2.imread(\"ori_stop_sign.png\")\n",
    "#img = cv2.imread(\"limit.jpg\")\n",
    "#img = cv2.imread(\"uw17-square-usstop-l1rectangles-less-256-epoch-999-area-downsizefirst.png\")\n",
    "#img = cv2.imread(\"uw17-square.jpg\")\n",
    "#img = cv2.imread(\"35.png\")\n",
    "#img = cv2.imread(\"adv_group 2.png\")\n",
    "#img = cv2.imread(\"Screenshotadv.png\")\n",
    "#img = cv2.imread('stop.jpg')\n",
    "#img = cv2.imread('stop-sign.jpg')\n",
    "#img = cv2.imread(\"image3.jpg\")\n",
    "img = cv2.imread(\"stop1.png\")\n",
    "img = remove(img)\n",
    "image = img.copy()\n",
    "blurImg = cv2.blur(img,(10,10)) \n",
    "\n",
    "\n",
    "#hsv = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "hsv = get_hsv(img)\n",
    "gray= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "# lower bound and upper bound for red color\n",
    "lower_red = np.array([160,50,50])\n",
    "upper_red = np.array([180,255,255])\n",
    "\n",
    "\n",
    "     \n",
    "# Threshold the HSV image using inRange function to get only red colors\n",
    "mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "# Segment only the detected region\n",
    "segmented_img = cv2.bitwise_and(img, img, mask=mask)\n",
    "# removeing unnecessary noise.\n",
    "#define kernel size  \n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "erosion = cv2.erode(img,kernel,iterations = 1)\n",
    "dilation = cv2.dilate(img,kernel,iterations = 1)\n",
    "opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "gradient = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)\n",
    "\n",
    "# Remove unnecessary noise from mask\n",
    "# mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)  #  cv2.MORPH_CLOSE removes unnecessary black noises from the white region.\n",
    "mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel) # cv2.MORPH_OPEN removes white noise from the black region of the mask.\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=[18,18])\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#plt.subplot(241);plt.imshow(image[:,:,::-1]);plt.title(\"Original Image\",fontdict={'fontsize': 15});plt.axis('off');\n",
    "plt.subplot(241);plt.imshow(image);plt.title(\"Original Image\",fontdict={'fontsize': 15});plt.axis('off');\n",
    "\n",
    "plt.subplot(242);plt.imshow(mask, cmap='gray');plt.title(\"Mask of red Color\",fontdict={'fontsize': 15});plt.axis('off');\n",
    "plt.subplot(243);plt.imshow(segmented_img[:,:,::-1]);plt.title(\"segmented_img\",fontdict={'fontsize': 15});plt.axis('off');\n",
    "plt.subplot(244);plt.imshow(erosion);plt.title(\"erosion\",fontdict={'fontsize': 15});plt.axis('off');\n",
    "plt.subplot(245);plt.imshow(dilation);plt.title(\"dilation\",fontdict={'fontsize': 15});plt.axis('off');\n",
    "plt.subplot(246);plt.imshow(opening);plt.title(\"opening\",fontdict={'fontsize': 15});plt.axis('off');\n",
    "plt.subplot(247);plt.imshow(closing);plt.title(\"closing\",fontdict={'fontsize': 15});plt.axis('off');\n",
    "plt.subplot(248);plt.imshow(gradient);plt.title(\"gradient\",fontdict={'fontsize': 15});plt.axis('off');\n",
    "\n",
    "#plt.figure(figsize=[13,13])\n",
    "\n",
    "#plt.subplot(121);plt.imshow(img[:,:,::-1]);plt.title(\"Original Image\",fontdict={'fontsize': 25});plt.axis('off');\n",
    "#plt.subplot(122);plt.imshow(mask, cmap='gray');plt.title(\"Mask of red Color\",fontdict={'fontsize': 25});plt.axis('off');\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "\n",
    "\n",
    "f = cv2.imread(\"adv_group 2.png\")\n",
    "f = remove_bg(f)\n",
    "blurred_f = ndimage.gaussian_filter(f, 3)\n",
    "\n",
    "filter_blurred_f = ndimage.gaussian_filter(blurred_f, 1)\n",
    "\n",
    "alpha = 30\n",
    "sharpened = blurred_f + alpha * (blurred_f - filter_blurred_f)\n",
    "\n",
    "gray= cv2.cvtColor(sharpened,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "        \n",
    "#mask = getcolormask(\"red\", image)    \n",
    "mask = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel) \n",
    "cnts, hier = cv2.findContours(gray, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "#mx = max(cnts, key = cv2.contourArea)\n",
    "cv2.drawContours(gray, cnts,  -1, (0,255,255), 2)  \n",
    "print(len(cnts))\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(gray , cmap='gray')\n",
    "\n",
    "plt.imshow(gray)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = cv2.imread('uw17-square.jpg')\n",
    "#img = cv2.imread(\"limit.jpg\")\n",
    "img = cv2.imread(\"adv_group 2.png\")\n",
    "\n",
    "#print (img.astype(np.float) )\n",
    "from skimage import img_as_ubyte\n",
    "img = img_as_ubyte(img)\n",
    "img = remove_bg(img)\n",
    "gradient = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)\n",
    "\n",
    "img = remove_noise(gradient)\n",
    "\n",
    "cnts, hier = cv2.findContours(img , cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.drawContours(img, cnts,  -1, (255,0,0), 1)\n",
    "#reader = easyocr.Reader(['en'], gpu=False)  #Hindi, telugu, and English\n",
    "#results = reader.readtext(img, detail=1, paragraph=False) #Set detail to 0 for simple text output\n",
    "\n",
    "\n",
    "#for (bbox, text, prob) in results:  \n",
    "#    #Define bounding boxes\n",
    "#    (tl, tr, br, bl) = bbox\n",
    "#    tl = (int(tl[0]), int(tl[1]))\n",
    "#    tr = (int(tr[0]), int(tr[1]))\n",
    "#    br = (int(br[0]), int(br[1]))\n",
    "#    bl = (int(bl[0]), int(bl[1]))\n",
    "    \n",
    "    #Remove non-ASCII characters to display clean text on the image (using opencv)\n",
    "#    text = \"\".join([c if ord(c) < 128 else \"\" for c in text]).strip()\n",
    "   \n",
    "    #Put rectangles and text on the image\n",
    "#    cv2.rectangle(img, tl, br, (0, 255, 0), 10)\n",
    " #   cv2.putText(img, text, (tl[0], tl[1] - 10), \n",
    " #               cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "# show the output image\n",
    "plt.imshow(img )\n",
    "#print(results)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = easyocr.Reader(['en'], gpu=False)  #Hindi, telugu, and English\n",
    "img = cv2.imread('uw17-square.jpg')\n",
    "img = img.copy()\n",
    "#img = cv2.imread('attac-stop.png')\n",
    "#img = cv2.imread('uw17-square-usstop-l1rectangles-less-256-epoch-999-area-downsizefirst.png')\n",
    "\n",
    "\n",
    "img =getcolormask(\"red\", img )\n",
    "\n",
    "\n",
    "results = reader.readtext(img, detail=1, paragraph=False) #Set detail to 0 for simple text output\n",
    "#Paragraph=True will combine all results making it easy to capture it in a dataframe. \n",
    "\n",
    "\n",
    "#To display the text on the original image or show bounding boxes\n",
    "#we need the coordinates for the text. So make sure the detail=1 above, readtext.\n",
    "# display the OCR'd text and associated probability\n",
    "for (bbox, text, prob) in results:  \n",
    "    #Define bounding boxes\n",
    "    (tl, tr, br, bl) = bbox\n",
    "    tl = (int(tl[0]), int(tl[1]))\n",
    "    tr = (int(tr[0]), int(tr[1]))\n",
    "    br = (int(br[0]), int(br[1]))\n",
    "    bl = (int(bl[0]), int(bl[1]))\n",
    "    \n",
    "    #Remove non-ASCII characters to display clean text on the image (using opencv)\n",
    "    text = \"\".join([c if ord(c) < 128 else \"\" for c in text]).strip()\n",
    "   \n",
    "    #Put rectangles and text on the image\n",
    "    cv2.rectangle(img, tl, br, (0, 255, 0), 10)\n",
    "    cv2.putText(img, text, (tl[0], tl[1] - 10), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "# show the output image\n",
    "plt.imshow(img)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"speed_limit.jpg\")\n",
    "contour_list = []\n",
    "mask = getcolormask('red' , img)\n",
    "if cv2.countNonZero(mask) > min_area:\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "    for cnt in contours:       \n",
    "        if cv2.contourArea(cnt, True)<0:\n",
    "            contour_list.append(cnt)\n",
    "#    cnt_max = max(contour_list, key = cv2.contourArea)\n",
    "#    contour_list.remove(cnt_max)\n",
    "cv2.drawContours(img, contour_list,  -1, (0,255,0), 3)\n",
    "plt.imshow(img)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = cv2.imread(\"limit.jpg\")\n",
    "#img = cv2.imread('uw17-square.jpg')\n",
    "img = cv2.imread(\"22333.png\")\n",
    "\n",
    "#img = remove(img)\n",
    "#cnts, hierarchy = cv2.findContours(remove_noise(img), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts, hierarchy = get_contours(img)\n",
    "#print([hierarchy])\n",
    "#print(hierarchy[0][2][2])\n",
    "cv2.drawContours(img, cnts,  -1, (255,0,0), 3)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = cv2.imread(\"limit.jpg\")\n",
    "#img = cv2.imread(\"ori_stop_sign.png\")\n",
    "#img = cv2.imread(\"adv_group 2.png\")\n",
    "#img = cv2.imread(\"41.png\")\n",
    "\n",
    "\n",
    "img = cv2.imread(\"attac-stop.png\")\n",
    "#img = cv2.imread(\"stop.jpg\")\n",
    "#img = cv2.imread(\"image3.jpg\")\n",
    "                 \n",
    "                 \n",
    "img = remove(img)\n",
    "\n",
    "print(img.shape)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = cv2.imread(\"limit.jpg\")\n",
    "#img = cv2.imread(\"stop-sign.jpg\")\n",
    "img = cv2.imread(\"uw17-square.jpg\")\n",
    "#img = cv2.imread(\"ori_stop_sign.png\")\n",
    "#img = cv2.imread(\"attac-stop.png\")\n",
    "#img = cv2.imread(\"stop.jpg\")\n",
    "\n",
    "\n",
    "colors_present = get_color(img)\n",
    "\n",
    "plt.imshow(img[:,:,::-1])\n",
    "has_color(colors_present)        \n",
    "print(colors_present)          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_present, shape = get_shape(img)\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "frjRk5n5KRu1"
   },
   "outputs": [],
   "source": [
    "#img = gradient\n",
    "#img = cv2.imread(\"stop-sign.jpg\")\n",
    "#img = cv2.imread(\"limit.jpg\")\n",
    "\n",
    "result = recognize_text(img)\n",
    "has_word(result)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = cv2.imread(\"adv_group 2.png\")\n",
    "#img = cv2.imread(\"output.png\")\n",
    "result = recognize_text(img)\n",
    "has_word(result)\n",
    "print(result)\n",
    "plt.imshow(img[:,:,::-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = cv2.imread(\"limit.jpg\")\n",
    "#img = cv2.imread(\"adv_group 2.png\")\n",
    "#img = cv2.imread(\"ori_stop_sign.png\")\n",
    "#img = cv2.imread(\"attac-stop.png\")\n",
    "#img = cv2.imread(\"stop.jpg\")\n",
    "\n",
    "colors_present = get_color(img)\n",
    "\n",
    "plt.imshow(img[:,:,::-1])\n",
    "has_color(colors_present)        \n",
    "print(colors_present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A text file is created and flushed\n",
    "with open(\"recognized.txt\", \"w+\") as file:\n",
    "    for item in texts:\n",
    "        # write each item on a new line\n",
    "        file.write(\"\\n has_word({})\".format(item.split(None , -1)))\n",
    "    print('Done')\n",
    "\n",
    "file.close()\n",
    "     \n",
    "# Close the file\n",
    "file.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"limit.jpg\")\n",
    "#img = cv2.imread(\"ori_stop_sign.png\")\n",
    "#img = cv2.imread(\"attac-stop.png\")\n",
    "#img = cv2.imread(\"stop.jpg\")\n",
    "\n",
    "\n",
    "colors_present =[]\n",
    "colors_list = ['red', 'blue', 'black', 'white', 'yellow']\n",
    "\n",
    "for color in colors_list:\n",
    "    mask = getcolormask(color , get_hsv(img))\n",
    "    contours,hierarchy = get_contours(mask)\n",
    "\n",
    "    if cv2.countNonZero(mask) > img.size/1000 and (hierarchy[i][2] >-1 or hierarchy[i][3] >-1):  # a contour should have at least a child or a parent\n",
    "        colors_present.append(color)\n",
    "\n",
    "plt.imshow(img[:,:,::-1])\n",
    "has_color(colors_present)        \n",
    "print(colors_present)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cv2.countNonZero(mask) > 0:\n",
    "    writ(\"has_colour({})\"\".format(red))\n",
    "    print('Red is present!')\n",
    "    else:\n",
    "        print('Red is not present!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# load image as grayscale\n",
    "img = cv2.imread('attac-stop.png')\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# threshold input image using otsu thresholding as mask and refine with morphology\n",
    "ret, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU) \n",
    "kernel = np.ones((9,9), np.uint8)\n",
    "mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# put mask into alpha channel of result\n",
    "result = img.copy()\n",
    "result = cv2.cvtColor(result, cv2.COLOR_BGR2BGRA)\n",
    "result[:, :, 3] = mask\n",
    "\n",
    "# save resulting masked image\n",
    "cv2.imwrite('retina_masked.png', result)\n",
    "plt.imshow(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = cv2.imread('limit.jpg')\n",
    "\n",
    "circles = cv2.HoughCircles(remove_noise(img), \n",
    "                   cv2.HOUGH_GRADIENT, 1, 100)\n",
    "print(circles)\n",
    "print(np.around(circles))\n",
    "circles = np.uint16(np.around(circles))\n",
    "# Draw the circles\n",
    "for i in circles[0,:]:\n",
    "    # draw the outer circle\n",
    "    cv2.circle(img,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "    # draw the center of the circle\n",
    "    cv2.circle(img,(i[0],i[1]),2,(0,0,255),3)\n",
    "plt.imshow(img)\n",
    "\n",
    "#if circles is not None:\n",
    "#print(len(detected_circles))  \n",
    "print(img.size/3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getContours(img):\n",
    "    contours,hierarchy = cv2.findContours(img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        print(area)\n",
    "        if area>500:\n",
    "            cv2.drawContours(imgContour, cnt, -1, (255, 0, 0), 3)\n",
    "            peri = cv2.arcLength(cnt,True)\n",
    "            #print(peri)\n",
    "            approx = cv2.approxPolyDP(cnt,alpha*peri,True)\n",
    "            print(len(approx))\n",
    "            objCor = len(approx)\n",
    "            x, y, w, h = cv2.boundingRect(approx)\n",
    " \n",
    "            if objCor ==3: objectType =\"Tri\"\n",
    "            elif objCor == 4:\n",
    "                aspRatio = w/float(h)\n",
    "                if aspRatio >0.98 and aspRatio <1.03: objectType= \"Square\"\n",
    "                else:objectType=\"Rectangle\"\n",
    "            elif objCor>4: objectType= \"Circles\"\n",
    "            else:objectType=\"None\"\n",
    " \n",
    " \n",
    " \n",
    "            cv2.rectangle(imgContour,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            cv2.putText(imgContour,objectType,\n",
    "                        (x+(w//2)-10,y+(h//2)-10),cv2.FONT_HERSHEY_COMPLEX,0.7,\n",
    "                        (0,0,0),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GRRtoph_hMAr"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(\"limit.jpg\")\n",
    "blur = cv2.GaussianBlur(img, (5,5), 0)\n",
    "\n",
    "\n",
    "#we convert the image to an hsv image because hsv helps to differentiate intensity from color. \n",
    "# hue, which is the color or shade of the pixel. \n",
    "# The saturation is the intensity of the color. \n",
    "# A saturation of 0 is white, and a saturation of 255 is maximum intensity. \n",
    "\n",
    "\n",
    "hsv = cv2.cvtColor(blur,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "bilateral_filtered_image = cv2.bilateralFilter(img, 5, 175, 175, borderType=cv2.BORDER_CONSTANT)\n",
    "\n",
    "edge_detected_image = cv2.Canny(bilateral_filtered_image, 70, 200)\n",
    "cv2.imshow('Edge', edge_detected_image)\n",
    "\n",
    "\n",
    "# lower bound and upper bound for Yellow color\n",
    "lower_bound_Y = np.array([20, 80, 80])   \n",
    "upper_bound_Y = np.array([30, 255, 255])\n",
    "mask_Y = cv2.inRange(hsv, lower_bound_Y, upper_bound_Y)\n",
    "contours_Y, hierarchy_Y = cv2.findContours(mask_Y.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "output = cv2.drawContours(mask_Y, contours_Y, -1, (0, 255, 0), 3)\n",
    "\n",
    "# lower bound and upper bound for Green color\n",
    "lower_bound_G = np.array([50, 20, 20])   \n",
    "upper_bound_G = np.array([100, 255, 255])\n",
    "mask_G = cv2.inRange(hsv, lower_bound_G, upper_bound_G)\n",
    "\n",
    "# lower bound and upper bound for red color\n",
    "lower_bound_R = np.array([160,50,50])\n",
    "upper_bound_R = np.array([180,255,255])\n",
    "#lower_bound_R = np.array([100,100,50])\n",
    "#upper_bound_R = np.array([255,153,153])\n",
    "mask_R = cv2.inRange(hsv, lower_bound_R, upper_bound_R)\n",
    "contours_R, hierarchy_R = cv2.findContours(mask_R.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#output_R = cv2.drawContours(img, contours_R, -1, (0, 255, 0), 5)\n",
    "#print(len(contours_R))\n",
    "\n",
    "\n",
    "\n",
    "# lower bound and upper bound for white color\n",
    "\n",
    "lower_bound_W = np.array([0,0,168])\n",
    "upper_bound_W = np.array([172,111,255])\n",
    "mask_W = cv2.inRange(hsv, lower_bound_W, upper_bound_W)\n",
    "contours_W, hierarchy_W = cv2.findContours(mask_W.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contour_list_W = []\n",
    "areas_W = []\n",
    "for i, cnt in enumerate(contours_W):\n",
    "    area = cv2.contourArea(cnt)\n",
    "    if (area > img.size/2000) and (area < img.size/3.1 ) :\n",
    "        contour_list_W.append(cnt)\n",
    "        areas_W.append(area)\n",
    "#output_W = cv2.drawContours(img, contour_list_W, -1, (0, 255, 255), 5)\n",
    "#print(len(contour_list_W))\n",
    "#print(areas_W )\n",
    "\n",
    "# lower bound and upper bound for black color\n",
    "lower_bound_B = np.array([0, 0, 0])\n",
    "upper_bound_B = np.array([[180, 255, 40]])\n",
    "#upper_bound_B = np.array([179,100,130])\n",
    "mask_B = cv2.inRange(hsv, lower_bound_B, upper_bound_B)\n",
    "contours_B, hierarchy_B = cv2.findContours(mask_B.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contour_list_B = []\n",
    "areas_B = []\n",
    "for i, cnt in enumerate(contours_B):\n",
    "    area = cv2.contourArea(cnt)\n",
    "    if (area > img.size/2000) and (area < img.size/3.1 ) :\n",
    "        contour_list_B.append(cnt)\n",
    "        areas_B.append(area)\n",
    "output_B = cv2.drawContours(img, contour_list_B, -1, (0, 255, 255), 5)\n",
    "print(len(contour_list_B))\n",
    "\n",
    "# lower bound and upper bound for blue color\n",
    "lower_bound_Blue = np.array([110,50,50])\n",
    "upper_bound_Blue = np.array([130,255,255])\n",
    "mask_Blue = cv2.inRange(hsv, lower_bound_Blue, upper_bound_Blue)\n",
    "\n",
    "\n",
    "plt.figure(figsize=[30,30])\n",
    "\n",
    "plt.subplot(4,2,1);plt.imshow(img[:,:,::-1]);plt.title(\"Original Image\",fontdict={'fontsize': 15});plt.axis('off');\n",
    "plt.subplot(4,2,2);plt.imshow(mask_Y, cmap='gray');plt.title(\"Mask of yellow Color\",fontdict={'fontsize': 17});plt.axis('off');\n",
    "plt.subplot(4,2,3);plt.imshow(mask_G, cmap='gray');plt.title(\"Mask of green Color\",fontdict={'fontsize': 17});plt.axis('off');\n",
    "plt.subplot(4,2,4);plt.imshow(mask_R, cmap='gray');plt.title(\"Mask of red Color\",fontdict={'fontsize': 17});plt.axis('off');\n",
    "plt.subplot(4,2,5);plt.imshow(mask_W, cmap='gray');plt.title(\"Mask of white Color\",fontdict={'fontsize': 17});plt.axis('off');\n",
    "plt.subplot(4,2,6);plt.imshow(mask_B, cmap='gray');plt.title(\"Mask of black Color\",fontdict={'fontsize': 17});plt.axis('off');\n",
    "plt.subplot(4,2,7);plt.imshow(mask_Blue, cmap='gray');plt.title(\"Mask of blue Color\",fontdict={'fontsize': 17});plt.axis('off');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ba6UwHJ-lkUc",
    "outputId": "16be4c30-0cb4-4564-f359-f0c80d8ab039"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#img = cv2.imread('attac-stop.png')\n",
    "#img = cv2.imread('stop-sign.jpg')\n",
    "#img = cv2.imread(\"ori_stop_sign.png\")\n",
    "#img = cv2.imread(\"image3.jpg\")\n",
    "img = cv2.imread(\"limit.jpg\")\n",
    "#img = cv2.imread(\"uw17-square-usstop-l1rectangles-less-256-epoch-999-area-downsizefirst.png\")\n",
    "#img = cv2.imread(\"uw17-square.jpg\")\n",
    "#img = cv2.imread(\"35.png\")\n",
    "#img = cv2.imread(\"adv_group 2.png\")\n",
    "#img = cv2.imread('stop.jpg'\n",
    "\n",
    "bilateral_filtered_image = cv2.bilateralFilter(img, 5, 175, 175, borderType=cv2.BORDER_CONSTANT)\n",
    "\n",
    "edge_detected_image = cv2.Canny(bilateral_filtered_image, 70, 200)\n",
    "cv2.imshow('Edge', edge_detected_image)\n",
    "\n",
    "\n",
    "#img = cv2.imread('adv_group 2.png')\n",
    "\n",
    "#original = img.copy()\n",
    "\n",
    "#hsv = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "#lower_red = np.array([160,50,50])\n",
    "#upper_red = np.array([180,255,255])\n",
    "     \n",
    "# Threshold the HSV image using inRange function to get only red colors\n",
    "#mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "#segmented_img = cv2.bitwise_and(img, img, mask=mask)\n",
    "gray = cv2.cvtColor(bilateral_filtered_image, cv2.COLOR_BGR2GRAY)\n",
    "#edges= cv2.Canny(gray, 50,200)\n",
    "\n",
    "\n",
    "#ret, thresh = cv2.threshold(gray, 127, 255, 0)\n",
    "#th3 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n",
    "#thresh = cv2.adaptiveThreshold(gray, 255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 21, 4)\n",
    "\n",
    "#cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts, hierarchy = cv2.findContours( edge_detected_image, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_NONE)\n",
    "hierarchy = hierarchy[0]\n",
    "\n",
    "contour_list = []\n",
    "areas = []\n",
    "for i, cnt in enumerate(cnts):\n",
    "      \n",
    "    epsilon = 0.05*cv2.arcLength(cnt,True)\n",
    "#    approx = cv2.approxPolyDP(cnt,epsilon,True)\n",
    "    area = cv2.contourArea(cnt)\n",
    "    if (area > 100) and (area < img.size/3.1 ) :\n",
    "        contour_list.append(cnt)\n",
    "        areas.append(area)\n",
    "# compute the area of the contour along with the bounding box\n",
    "# to compute the aspect ratio\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        aspectRatio = w / float(h)\n",
    "        extent = area / float(w * h)\n",
    "        \n",
    "        \n",
    "# compute the convex hull of the contour, then use the area of the\n",
    "# original contour and the area of the convex hull to compute the solidity\n",
    "#    hull = cv2.convexHull(cnt)\n",
    "#    hullArea = cv2.contourArea(hull)\n",
    "#ÃŸ    solidity = area / float(hullArea)\n",
    "#    if hierarchy[i][2] < 0 and hierarchy[i][3] < 0:\n",
    "#        cv2.drawContours(img, cnts, i, (0, 0, 255), 5)\n",
    "#    else:\n",
    "#        cv2.drawContours(img, cnts, i, (0, 255, 0), 5)  \n",
    "\n",
    "outer_contour = np.argmax(areas)     \n",
    "print(areas) \n",
    "print(outer_contour)\n",
    "print(img.size/3.05)\n",
    "        \n",
    "#print(cnts)\n",
    "#cv2. RETR_TREE, cv2.RETR_EXTERNAL cv2.CHAIN_APPROX_NONE cv2.CHAIN_APPROX_SIMPLE\n",
    "#cv2.contourArea\n",
    "#cv2.minEnclosingCircle(cnt)\n",
    "\n",
    "\n",
    "#cv2.drawContours(img, contour_list, outer_contour, (0,255,0), 3)\n",
    "cv2.drawContours(img, contour_list, -1, (0,255,0), 3)\n",
    "\n",
    "number_of_objects_in_image= len(contour_list)\n",
    "print (\"The number of objects in this image: \", str(number_of_objects_in_image))\n",
    "\n",
    "plt.figure(figsize=[12,12])\n",
    "plt.subplot(121);plt.imshow(img[:,:,::-1]);plt.title(\"Original Image\",fontdict={'fontsize': 15});plt.axis('off');\n",
    "#plt.subplot(122);plt.imshow(bilateral_filtered_image[:,:,::-1]);plt.title(\"Threshold Image\",fontdict={'fontsize': 15});plt.axis('off');\n",
    "plt.subplot(122);plt.imshow(edge_detected_image)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "for cnt in cnts:\n",
    "    approx = cv2.approxPolyDP(cnt,alpha*cv2.arcLength(cnt,True),True)\n",
    "    print(approx)\n",
    "    print(len(approx))\n",
    "    if len(approx)==5:\n",
    "        print(\"Blue = pentagon\")\n",
    "        cv2.drawContours(img,[cnt],0,255,-1)\n",
    "    elif len(approx)==3:\n",
    "        print(\"Green = triangle\")\n",
    "        cv2.drawContours(img,[cnt],0,(0,255,0),-1)\n",
    "    elif len(approx)==4:\n",
    "        print(\"Red = square\")\n",
    "        cv2.drawContours(img,[cnt],0,(0,0,255),-1)\n",
    "    elif len(approx) == 6:\n",
    "        print(\"Cyan = Hexa\")\n",
    "        cv2.drawContours(img,[cnt],0,(255,255,0),-1)\n",
    "    elif len(approx) == 8:\n",
    "        print(\"White = Octa\")\n",
    "        cv2.drawContours(img,[cnt],0,(255,255,255),-1)\n",
    "    elif len(approx) > 12:\n",
    "        print(\"Yellow = circle\")\n",
    "        cv2.drawContours(img,[cnt],0,(0,255,255),-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imported image and processing (shorthand here)\n",
    "image = cv2.imread(args[\"image\"])\n",
    "blur = cv2.GaussianBlur(image, (5,5), 0)\n",
    "blur_hsv = cv2.cvtColor(blur, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# set regions of color \n",
    "boundaries = [\n",
    "    # black \n",
    "    ([0,0,0],[180, 255, 40])\n",
    "\n",
    "    #pink\n",
    "    #([151, 80, 50], [174, 255, 255])   \n",
    "]\n",
    "\n",
    "# loop over the boundaries\n",
    "for (lower, upper) in boundaries:\n",
    "    # create NumPy arrays from the boundaries\n",
    "    lower = np.array(lower, dtype = \"uint8\")\n",
    "    upper = np.array(upper, dtype = \"uint8\")\n",
    "\n",
    "    # find the colors within the specified boundaries and apply\n",
    "    mask = cv2.inRange(blur_hsv, lower, upper)  \n",
    "    output = cv2.bitwise_and(image, image, mask = mask)\n",
    "\n",
    "    # show the images\n",
    "    cv2.imshow(\"images\", np.hstack([image, output]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_T9Gee-i-rV"
   },
   "source": [
    "Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install colorthief\n",
    "!pip3 install webcolors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webcolors\n",
    "from scipy.spatial import KDTree\n",
    "from webcolors import (CSS3_HEX_TO_NAMES,hex_to_rgb,)\n",
    "def convert_rgb_to_names(rgb_tuple):\n",
    "    \n",
    "    # a dictionary of all the hex and their respective names in css3\n",
    "    css3_db = CSS3_HEX_TO_NAMES\n",
    "    names = []\n",
    "    rgb_values = []\n",
    "    for color_hex, color_name in css3_db.items():\n",
    "        names.append(color_name)\n",
    "        rgb_values.append(hex_to_rgb(color_hex))\n",
    "    \n",
    "    kdt_db = KDTree(rgb_values)\n",
    "    distance, index = kdt_db.query(rgb_tuple)\n",
    "    return f'closest match: {names[index]}'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img = \"limit.jpg\"\n",
    "from colorthief import ColorThief\n",
    "color_thief = ColorThief(img)\n",
    "dominant_color = color_thief.get_color(quality=1)\n",
    "palette = color_thief.get_palette(color_count=2)\n",
    "plt.imshow([[palette[i] for i in range(3)]])\n",
    "plt.show()\n",
    "print([palette])\n",
    "print(dominant_color)\n",
    "#webcolors.rgb_to_name((5, 5, 5))\n",
    "convert_rgb_to_names(dominant_color)\n",
    "\n",
    "\n",
    "#im.getcolors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AVERANGE COLOR, MIN, MAX, STANDARD DEVIATION\n",
    "#SELECT ONLY NOT TRANSPARENT COLOR\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import sys\n",
    "import os\n",
    "import os.path\n",
    "from os import path\n",
    "import numpy as np\n",
    "import math \n",
    "\n",
    "\n",
    "\n",
    "def compute_average_image_color(img_path):\n",
    "\n",
    "    if not os.path.isfile(img_path):\n",
    "        print(path_inp_image, 'DONT EXISTS, EXIT')\n",
    "        sys.exit()\n",
    "\n",
    "    \n",
    "    #load image\n",
    "    img = Image.open(img_path).convert('RGBA')\n",
    "    img = img.resize((50,50))  # Small optimization\n",
    "\n",
    "\n",
    "    #DEFINE SOME VARIABLES\n",
    "    width, height = img.size\n",
    "    r_total = 0\n",
    "    g_total = 0\n",
    "    b_total = 0\n",
    "    count = 0\n",
    "    red_list=[]\n",
    "    green_list=[]\n",
    "    blue_list=[]\n",
    "    \n",
    "    \n",
    "    #READ AND CHECK PIXEL BY PIXEL\n",
    "    for x in range(0, width):\n",
    "        for y in range(0, height):\n",
    "            r, g, b, alpha = img.getpixel((x,y))\n",
    "            \n",
    "            if alpha !=0:\n",
    "                red_list.append(r)\n",
    "                green_list.append(g)\n",
    "                blue_list.append(b)\n",
    "            \n",
    "                r_total += r\n",
    "                g_total += g\n",
    "                b_total += b\n",
    "                count += 1\n",
    "\n",
    "            \n",
    "    #CALCULATE THE AVRANGE COLOR, MIN, MAX, ETC             \n",
    "    average_color=(round(r_total/count), round(g_total/count), round(b_total/count))\n",
    "    print(average_color)\n",
    "    \n",
    "    red_list.sort()\n",
    "    green_list.sort()\n",
    "    blue_list.sort()\n",
    "\n",
    "    \n",
    "    red_min_max=[]\n",
    "    green_min_max=[]\n",
    "    blue_min_max=[]\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    red_min_max.append(min(red_list))\n",
    "    red_min_max.append(max(red_list))\n",
    "    green_min_max.append(min(green_list))\n",
    "    green_min_max.append(max(red_list))\n",
    "    blue_min_max.append(min(blue_list))\n",
    "    blue_min_max.append(max(blue_list))\n",
    "    \n",
    "    print('red_min_max: ', red_min_max)\n",
    "    print('green_min_max: ', green_min_max)\n",
    "    print('blue_min_max: ', blue_min_max)\n",
    "\n",
    "\n",
    "\n",
    "    #variance and standard devietion\n",
    "    red_stddev=round(math.sqrt(np.var(red_list)))\n",
    "    green_stddev=round(math.sqrt(np.var(green_list)))\n",
    "    blue_stddev=round(math.sqrt(np.var(blue_list)))\n",
    "\n",
    "    print('red_stddev: ', red_stddev)\n",
    "    print('green_stddev: ', green_stddev)\n",
    "    print('blue_stddev: ', blue_stddev)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img_path='adv_group 2.png'\n",
    "compute_average_image_color(img_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # DataFlair background removal\n",
    "# import necessary packages\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "# store background images in a list\n",
    "\n",
    "# initialize mediapipe\n",
    "mp_selfie_segmentation = mp.solutions.selfie_segmentation\n",
    "selfie_segmentation = mp_selfie_segmentation.SelfieSegmentation(model_selection=1)\n",
    "\n",
    "frame = cv2.imread('ori_stop_sign.png')\n",
    "height , width, channel = frame.shape\n",
    "\n",
    "RGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "  # get the result\n",
    "results = selfie_segmentation.process(RGB)\n",
    "  # extract segmented mask\n",
    "mask = results.segmentation_mask\n",
    "  # show outputs\n",
    "plt.imshow( mask)\n",
    "#plt.imshow( frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZyyxdKwU5Smo"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('ori_stop_sign.png')\n",
    "\n",
    "# get grayscale image\n",
    "def get_grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# noise removal\n",
    "def remove_noise(image):\n",
    "    return cv2.medianBlur(image,5)\n",
    " \n",
    "#thresholding\n",
    "def thresholding(image):\n",
    "    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "#dilation\n",
    "def dilate(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.dilate(image, kernel, iterations = 1)\n",
    "    \n",
    "#erosion\n",
    "def erode(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.erode(image, kernel, iterations = 1)\n",
    "\n",
    "#opening - erosion followed by dilation\n",
    "def opening(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "#canny edge detection\n",
    "def canny(image):\n",
    "    return cv2.Canny(image, 100, 200)\n",
    "\n",
    "#skew correction\n",
    "def deskew(image):\n",
    "    coords = np.column_stack(np.where(image > 0))\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated\n",
    "\n",
    "#template matching\n",
    "def match_template(image, template):\n",
    "    return cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "id": "ywEQWz_E6pWG",
    "outputId": "07c1de6e-2440-4450-fed6-5e79375daf35"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.subplot(141);plt.imshow(img)\n",
    "#plt.subplot(142);plt.imshow(thresholding)\n",
    "plt.subplot(143);plt.imshow(opening)\n",
    "plt.subplot(144);plt.imshow(canny)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1riZM5pq8bOT",
    "outputId": "6f91fed6-2f5f-496f-c14d-dc08778c2009"
   },
   "outputs": [],
   "source": [
    "print(d['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 257
    },
    "id": "HUaC_oJR8k9V",
    "outputId": "b7c42fb4-04cb-4f7a-ff12-67d98cebfa0f"
   },
   "outputs": [],
   "source": [
    "n_boxes = len(d['text'])\n",
    "for i in range(n_boxes):\n",
    "    if int(d['conf'][i]) > 60:\n",
    "        (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n",
    "        img = cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "plt.imshow( img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2WwtnRQjQX5"
   },
   "source": [
    "*Colour* detection **bold text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "8ubS1gzZWjpN",
    "outputId": "93fa1430-4011-44a9-fef7-a9e0d0060db7"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(\"ori_stop_sign.png\")\n",
    "\n",
    "# convert to hsv colorspace\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "# lower bound and upper bound for Green color\n",
    "lower_bound = np.array([50, 20, 20])   \n",
    "upper_bound = np.array([100, 255, 255])\n",
    "# find the colors within the boundaries\n",
    "mask = cv2.inRange(hsv, lower_bound, upper_bound)\n",
    "\n",
    "#define kernel size  \n",
    "kernel = np.ones((30,30),np.uint8)\n",
    "# Remove unnecessary noise from mask\n",
    "# mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "\n",
    "plt.figure(figsize=[13,13])\n",
    "\n",
    "plt.subplot(121);plt.imshow(img[:,:,::-1]);plt.title(\"Original Image\",fontdict={'fontsize': 25});plt.axis('off');\n",
    "plt.subplot(122);plt.imshow(mask, cmap='gray');plt.title(\"Mask of green Color\",fontdict={'fontsize': 25});plt.axis('off');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VNK-BVWrl8ir"
   },
   "outputs": [],
   "source": [
    "#Maximally Stable Extremal Regions - MSER algorithm:\n",
    "mser = cv2.MSER_create(_min_area=100,_max_area=10000)\n",
    "regions_ red, _ = mser.detectRegions(red_normalize.astype('uint8'))\n",
    "regions_blue, _ = mser.detectRegions(blue_normalize.astype('uint8'))\n",
    "\n",
    "#we chose min area 100 and max area 10k for mser detection so that we donâ€™t have too many noise and small regions. . Once MSER \n",
    "#regions are detected a binary image for both the red and green mser regions are formed as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xw5YzhvkZiED"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('limit.jpg')\n",
    "cv2.HoughCircles(img, method, dp, minDist[, circles[, param1[, param2[, minRadius[, maxRadius]]]]]) â†’ circlesÂ¶\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r02LXdgZZhnY"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COvWuFg0jGhq"
   },
   "source": [
    "# New section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G-ojOwgUnWR_"
   },
   "outputs": [],
   "source": [
    " import cv2\n",
    "import numpy as np\n",
    "  \n",
    "# Read image.\n",
    "img = cv2.imread('limit.jpg', cv2.IMREAD_COLOR)\n",
    "  \n",
    "# Convert to grayscale.\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "  \n",
    "# Blur using 3 * 3 kernel.\n",
    "gray_blurred = cv2.blur(gray, (3, 3))\n",
    "  \n",
    "# Apply Hough transform on the blurred image.\n",
    "detected_circles = cv2.HoughCircles(gray_blurred, \n",
    "                   cv2.HOUGH_GRADIENT, 1, 20, param1 = 50,\n",
    "               param2 = 30, minRadius = 1, maxRadius = 40)\n",
    "  \n",
    "# Draw circles that are detected.\n",
    "if detected_circles is not None:\n",
    "  \n",
    "    # Convert the circle parameters a, b and r to integers.\n",
    "    detected_circles = np.uint16(np.around(detected_circles))\n",
    "  \n",
    "    for pt in detected_circles[0, :]:\n",
    "        a, b, r = pt[0], pt[1], pt[2]\n",
    "  \n",
    "        # Draw the circumference of the circle.\n",
    "        cv2.circle(img, (a, b), r, (0, 255, 0), 2)\n",
    "  \n",
    "        # Draw a small circle (of radius 1) to show the center.\n",
    "        cv2.circle(img, (a, b), 1, (0, 0, 255), 3)\n",
    "\n",
    "        cv2.imshow(\"Detected Circle\", img)\n",
    "        cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B7TZTa_r3UKm"
   },
   "outputs": [],
   "source": [
    "# contour and shape detection\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "def stackImages(scale,imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range ( 0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor= np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver\n",
    " \n",
    "def getContours(img):\n",
    "    contours,hierarchy = cv2.findContours(img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        print(area)\n",
    "        if area>1000:\n",
    "            #cv2.drawContours(imgContour, cnt, -1, (255, 0, 0), 3)\n",
    "            peri = cv2.arcLength(cnt,True)\n",
    "            #print(peri)\n",
    "            approx = cv2.approxPolyDP(cnt,alpha*peri,True)\n",
    "            print(len(approx))\n",
    "            objCor = len(approx)\n",
    "            x, y, w, h = cv2.boundingRect(approx)\n",
    " \n",
    "            if objCor ==3: objectType =\"Tri\"\n",
    "            elif objCor == 4:\n",
    "                aspRatio = w/float(h)\n",
    "                if aspRatio >0.98 and aspRatio <1.03: objectType= \"Square\"\n",
    "                else:objectType=\"Rectangle\"\n",
    "            elif objCor>4: objectType= \"Circles\"\n",
    "            else:objectType=\"None\"\n",
    " \n",
    " \n",
    " \n",
    "            cv2.rectangle(imgContour,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            cv2.putText(imgContour,objectType,\n",
    "                        (x+(w//2)-10,y+(h//2)-10),cv2.FONT_HERSHEY_COMPLEX,0.7,\n",
    "                        (0,0,0),2)\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "path = 'ori_stop_sign.png'\n",
    "img = cv2.imread(path)\n",
    "imgContour = img.copy()\n",
    " \n",
    "imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "imgBlur = cv2.GaussianBlur(imgGray,(7,7),1)\n",
    "imgCanny = cv2.Canny(imgBlur,50,50)\n",
    "getContours(imgCanny)\n",
    " \n",
    "imgBlank = np.zeros_like(img)\n",
    "imgStack = stackImages(0.8,([img,imgGray,imgBlur],\n",
    "                            [imgCanny,imgContour,imgBlank]))\n",
    " \n",
    "cv2.imshow(\"Stack\", imgStack)\n",
    " \n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "id": "Uom16Unky8IY",
    "outputId": "62e49904-a57e-4b89-f9d1-b048d53a0a11"
   },
   "outputs": [],
   "source": [
    "#Colour detection\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "def empty(a):\n",
    "    pass\n",
    " \n",
    "def stackImages(scale,imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range ( 0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor= np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver\n",
    " \n",
    " \n",
    " \n",
    "path = '/content/ori_stop_sign.png'\n",
    "cv2.namedWindow(\"TrackBars\")\n",
    "cv2.resizeWindow(\"TrackBars\",640,240)\n",
    "cv2.createTrackbar(\"Hue Min\",\"TrackBars\",0,179,empty)\n",
    "cv2.createTrackbar(\"Hue Max\",\"TrackBars\",19,179,empty)\n",
    "cv2.createTrackbar(\"Sat Min\",\"TrackBars\",110,255,empty)\n",
    "cv2.createTrackbar(\"Sat Max\",\"TrackBars\",240,255,empty)\n",
    "cv2.createTrackbar(\"Val Min\",\"TrackBars\",153,255,empty)\n",
    "cv2.createTrackbar(\"Val Max\",\"TrackBars\",255,255,empty)\n",
    " \n",
    "while True:\n",
    "    img = cv2.imread(path)\n",
    "    imgHSV = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "    h_min = cv2.getTrackbarPos(\"Hue Min\",\"TrackBars\")\n",
    "    h_max = cv2.getTrackbarPos(\"Hue Max\", \"TrackBars\")\n",
    "    s_min = cv2.getTrackbarPos(\"Sat Min\", \"TrackBars\")\n",
    "    s_max = cv2.getTrackbarPos(\"Sat Max\", \"TrackBars\")\n",
    "    v_min = cv2.getTrackbarPos(\"Val Min\", \"TrackBars\")\n",
    "    v_max = cv2.getTrackbarPos(\"Val Max\", \"TrackBars\")\n",
    "    print(h_min,h_max,s_min,s_max,v_min,v_max)\n",
    "    lower = np.array([h_min,s_min,v_min])\n",
    "    upper = np.array([h_max,s_max,v_max])\n",
    "    mask = cv2.inRange(imgHSV,lower,upper)\n",
    "    imgResult = cv2.bitwise_and(img,img,mask=mask)\n",
    " \n",
    " \n",
    "    # cv2.imshow(\"Original\",img)\n",
    "    # cv2.imshow(\"HSV\",imgHSV)\n",
    "    # cv2.imshow(\"Mask\", mask)\n",
    "    # cv2.imshow(\"Result\", imgResult)\n",
    " \n",
    "    imgStack = stackImages(0.6,([img,imgHSV],[mask,imgResult]))\n",
    "    cv2.imshow(\"Stacked Images\", imgStack)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hog(img):\n",
    "    gx = cv.Sobel(img, cv.CV_32F, 1, 0)\n",
    "    gy = cv.Sobel(img, cv.CV_32F, 0, 1)\n",
    "    mag, ang = cv.cartToPolar(gx, gy)\n",
    "    bins = np.int32(bin_n*ang/(2*np.pi))    # quantizing binvalues in (0...16)\n",
    "    bin_cells = bins[:10,:10], bins[10:,:10], bins[:10,10:], bins[10:,10:]\n",
    "    mag_cells = mag[:10,:10], mag[10:,:10], mag[:10,10:], mag[10:,10:]\n",
    "    hists = [np.bincount(b.ravel(), m.ravel(), bin_n) for b, m in zip(bin_cells, mag_cells)]\n",
    "    hist = np.hstack(hists)     # hist is a 64 bit vector\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trackbar\n",
    "\n",
    "\n",
    "path =  \"attac-stop.png\"\n",
    "def callback(x):\n",
    "\tglobal Kernel_Size\n",
    "\t#assign trackbar position value to H,S,V High and low variable\n",
    "\tKernel_Size = cv2.getTrackbarPos('Kernel Size','controls')\n",
    "\n",
    "\n",
    "#create a seperate window named 'controls' for trackbar\n",
    "cv2.namedWindow('controls',2)\n",
    "cv2.resizeWindow(\"controls\", 550,10);\n",
    "\n",
    "#global variable\n",
    "Kernel_Size = 5\n",
    "\n",
    "#create trackbars \n",
    "cv2.createTrackbar('Kernel Size','controls',0,200,callback)\n",
    "\n",
    "\n",
    "while(1):\n",
    "\t#read source image\n",
    "\timg=cv2.imread(path)\n",
    "\t#convert sourece image to HSC color mode\n",
    "\thsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\tkernel = np.ones((Kernel_Size,Kernel_Size),np.uint8)\n",
    "\terosion = cv2.erode(img,kernel,iterations = 1)\n",
    "\tdilation = cv2.dilate(img,kernel,iterations = 1)\n",
    "\topening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "\tclosing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "\tgradient = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)\n",
    "\n",
    "\n",
    "\n",
    "\t#show image\n",
    "\tcv2.imshow('erosion',erosion)\n",
    "\tcv2.imshow('gradient',gradient)\n",
    "\t\n",
    "\t#waitfor the user to press escape and break the while loop \n",
    "\tk = cv2.waitKey(1) & 0xFF\n",
    "\tif k == 27:\n",
    "\t\tbreak\n",
    "\t\t\n",
    "#destroys all window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare contours       \n",
    "        \n",
    "#    contours_hsv,hierarchy_hsv = get_contours(remove_noise(img))\n",
    "#    contours_mask,hierarchy_mask = get_contours(mask)\n",
    "#    for i, contour_hsv  in enumerate(contours_hsv):\n",
    "#        for j, contour_mask in enumerate(contours_mask):\n",
    "#            if cv2.matchShapes(contour_mask,contour_hsv,1,0.0)>0.05:\n",
    "#                contour_list.append(contour_hsv)\n",
    "#   print(contour_hsv)        \n",
    "    \n",
    "    \n",
    "#    for i, hierarchy  in enumerate(hierarchy_hsv):\n",
    "#            if cv2.countNonZero(mask) > img.size/1000 and (hierarchy[i][2] >-1 or hierarchy[i][3] >-1): \n",
    "#            # a contour should have at least a child or a parent\n",
    "#             colors_present.append(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 --upgrade pip3\n",
    "!pip3 install pixellib\n",
    "import pixellib\n",
    "from pixellib.tune_bg import alter_bg\n",
    "\n",
    "#from tensorflow.python.keras.utils.data_utils import get_file\n",
    "#WEIGHTS_PATH_X = \"https://github.com/bonlime/keras-deeplab-v3-plus/releases/download/1.1/deeplabv3_xception_tf_dim_ordering_tf_kernels.h5\"\n",
    "#weights_path = get_file('deeplabv3_xception_tf_dim_ordering_tf_kernels.h5',WEIGHTS_PATH_X, cache_subdir='models')\n",
    "\n",
    "change_bg = alter_bg()\n",
    "change_bg.load_pascalvoc_model(\"deeplabv3_xception_tf_dim_ordering_tf_kernels.h5\")\n",
    "change_bg.change_bg_img(f_image_path = \"Train/Train_Neg_9.svg.png\",b_image_path = \"Train/Sky_landscape.jpeg\", output_image_name=\"Train/new_img.jpeg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# find those words that may be misspelled\n",
    "misspelled = spell.unknown(['something', 'is', 'hapenning', 'here'])\n",
    "print\n",
    "for word in misspelled:\n",
    "    # Get the one `most likely` answer\n",
    "    print(spell.correction(word))\n",
    "\n",
    "    # Get a list of `likely` options\n",
    "    print(spell.candidates(word))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
